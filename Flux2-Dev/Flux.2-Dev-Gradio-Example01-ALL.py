import torch
from diffusers import Flux2Pipeline
from datetime import datetime
from PIL import Image
import os
import warnings
import gradio as gr
import platform
import shutil
import signal
import sys
import gc
import atexit

try:
    import psutil
except Exception:
    psutil = None

# Set device and data type
if torch.cuda.is_available():
    device = "cuda"
    dtype = torch.bfloat16
elif torch.backends.mps.is_available():
    device = "mps"
    dtype = torch.float16
else:
    device = "cpu"
    dtype = torch.float32

print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device} | dtype: {dtype}")

def _bytes_to_gb(value_bytes):
    return f"{value_bytes / (1024 ** 3):.2f} GB"

def print_system_resources():
    print("=== ì‹œìŠ¤í…œ ìì› ì •ë³´ ===")
    print(f"OS: {platform.system()} {platform.release()} ({platform.machine()})")
    print(f"CPU ì½”ì–´: {os.cpu_count()}")

    if psutil is not None:
        mem = psutil.virtual_memory()
        print(f"RAM: {_bytes_to_gb(mem.available)} / {_bytes_to_gb(mem.total)} (ì‚¬ìš© ê°€ëŠ¥/ì „ì²´)")
    else:
        try:
            page_size = os.sysconf("SC_PAGE_SIZE")
            phys_pages = os.sysconf("SC_PHYS_PAGES")
            total_ram = page_size * phys_pages
            print(f"RAM: {_bytes_to_gb(total_ram)} (ì „ì²´)")
        except Exception:
            print("RAM: ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    try:
        disk = shutil.disk_usage(os.getcwd())
        print(f"ë””ìŠ¤í¬: {_bytes_to_gb(disk.free)} / {_bytes_to_gb(disk.total)} (ì‚¬ìš© ê°€ëŠ¥/ì „ì²´)")
    except Exception:
        print("ë””ìŠ¤í¬: ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    if torch.cuda.is_available():
        try:
            props = torch.cuda.get_device_properties(0)
            total_vram = _bytes_to_gb(props.total_memory)
            allocated = _bytes_to_gb(torch.cuda.memory_allocated(0))
            reserved = _bytes_to_gb(torch.cuda.memory_reserved(0))
            print(f"CUDA GPU: {props.name} | VRAM: {allocated} (ì‚¬ìš©ì¤‘) / {reserved} (ì˜ˆì•½) / {total_vram} (ì „ì²´)")
        except Exception:
            print("CUDA GPU: ì •ë³´ í™•ì¸ ì‹¤íŒ¨")
    elif torch.backends.mps.is_available():
        print("MPS: ì‚¬ìš© ê°€ëŠ¥ (GPU ë©”ëª¨ë¦¬ ì •ë³´ëŠ” ì§€ì›ë˜ì§€ ì•ŠìŒ)")

print_system_resources()

def cleanup_resources():
    global pipe, interface
    try:
        print("\n[ì¢…ë£Œ] ìì› í•´ì œ ì‹œì‘...")
        if "interface" in globals() and interface is not None:
            try:
                interface.close()
            except Exception:
                pass
        if "pipe" in globals() and pipe is not None:
            try:
                pipe.to("cpu")
            except Exception:
                pass
            pipe = None
        gc.collect()
        if torch.cuda.is_available():
            try:
                torch.cuda.empty_cache()
            except Exception:
                pass
        if hasattr(torch, "mps") and torch.backends.mps.is_available():
            try:
                torch.mps.empty_cache()
            except Exception:
                pass
        print("[ì¢…ë£Œ] ìì› í•´ì œ ì™„ë£Œ.")
    except Exception:
        print("[ì¢…ë£Œ] ìì› í•´ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ.")

def _handle_sigint(signum, frame):
    cleanup_resources()
    sys.exit(0)

signal.signal(signal.SIGINT, _handle_sigint)
atexit.register(cleanup_resources)

# Actually, more RAM is required to run this program. Not working in 32GB. More than 48GB RAM required.
# Load text-to-image pipeline
pipe = Flux2Pipeline.from_pretrained(
    "black-forest-labs/FLUX.2-dev", torch_dtype=dtype, low_cpu_mem_usage=True
)

# Device-specific pipeline setup
if device == "cuda" or device == "cpu":
    print("Using CUDA or CPU device optimizations...")
    pipe.to(device)
    pipe.enable_model_cpu_offload() # CUDAì—ì„œ CPU RAMì„ ì¼ë¶€ ì‚¬ìš©
    pipe.enable_attention_slicing() # ì•ˆì“°ë©´ GPU ë©”ëª¨ë¦¬ë¥¼ ë” ì‚¬ìš©í•¨(ì†)
    pipe.enable_sequential_cpu_offload() # ì•ˆì“°ë©´ CUDAì—ì„œ ëŠë¦¼
elif device == "mps":
    print("Using MPS device optimizations...")
    pipe.enable_attention_slicing() # ì•ˆì“°ë©´ GPU ë©”ëª¨ë¦¬ë¥¼ ë” ì‚¬ìš©í•¨(ì†)
    pipe.enable_vae_slicing() # VAEë„ ë©”ëª¨ë¦¬ ì ˆì•½
    pipe.enable_vae_tiling() # VAEë„ íƒ€ì¼ë§
    torch.mps.empty_cache()
    # MPS doesn't support cpu_offload well
else:
    print("No valid device found!!!")
    exit(1)

prompt_input = "Highly realistic, 4k, high-quality, high resolution, beautiful full body korean woman model photography. She has black, medium-length hair that reaches her shoulders, tied back in a casual yet stylish manner, wearing a red bikini. Her eyes are hazel, with a natural sparkle of happiness as she smiles. Her skin appears natural with visible pores. Orange hue, solid orange backdrop, using a camera setup that mimics a large aperture, f/1.4 --ar 9:16 --style raw."

def generate_image(
    prompt, width, height, guidance_scale, num_inference_steps, seed, strength
):
    try:
        # Run the pipeline
        image = pipe(
            prompt=prompt,
            width=width,
            height=height,
            guidance_scale=guidance_scale,
            num_inference_steps=num_inference_steps,
            generator=torch.Generator(device=device).manual_seed(seed),
        ).images[0]
        
        # Save with timestamp
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        script_name = os.path.splitext(os.path.basename(__file__))[0]
        filename = f"{script_name}_{timestamp}.png"
        image.save(filename)

        return image, f"âœ“ ì´ë¯¸ì§€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filename}"
    except Exception as e:
        return None, f"âœ— ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


# Create Gradio interface
with gr.Blocks(title="Flux.1-dev Image Generator") as interface:
    gr.Markdown("# ğŸ¨ Flux.1-dev Image Generator")
    gr.Markdown("AIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì—ì„œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

    with gr.Row():
        with gr.Column(scale=1):
            # Input parameters
            prompt = gr.Textbox(
                label="í”„ë¡¬í”„íŠ¸",
                value=prompt_input,
                lines=3,
                placeholder="ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª…ì„ ì…ë ¥í•˜ì„¸ìš” (77ë‹¨ì–´ ì´í•˜ ê¶Œì¥)",
                info="ìƒì„±í•˜ê³  ì‹¶ì€ ì´ë¯¸ì§€ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ì„¤ëª…ì…ë‹ˆë‹¤. ìì„¸í• ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤. ì˜ˆ: 'ì—¬ì, ë¯¸ì†Œ, í•´ë³€, ë¹¨ê°„ ë¹„í‚¤ë‹ˆ'",
            )

            with gr.Row():
                width = gr.Slider(
                    label="ì´ë¯¸ì§€ ë„ˆë¹„",
                    minimum=256,
                    maximum=1024,
                    step=64,
                    value=512,
                    info="ìƒì„±í•  ì´ë¯¸ì§€ì˜ ë„ˆë¹„ë¥¼ ì§€ì •í•©ë‹ˆë‹¤ (í”½ì…€). 64ì˜ ë°°ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.",
                )
                height = gr.Slider(
                    label="ì´ë¯¸ì§€ ë†’ì´",
                    minimum=256,
                    maximum=1024,
                    step=64,
                    value=1024,
                    info="ìƒì„±í•  ì´ë¯¸ì§€ì˜ ë†’ì´ë¥¼ ì§€ì •í•©ë‹ˆë‹¤ (í”½ì…€). 64ì˜ ë°°ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.",
                )

            with gr.Row():
                guidance_scale = gr.Slider(
                    label="Guidance Scale (í”„ë¡¬í”„íŠ¸ ê°•ë„)",
                    minimum=1.0,
                    maximum=20.0,
                    step=0.5,
                    value=4.0,
                    info="ëª¨ë¸ì´ í”„ë¡¬í”„íŠ¸ë¥¼ ì–¼ë§ˆë‚˜ ë”°ë¥¼ì§€ ì œì–´í•©ë‹ˆë‹¤. ë‚®ì„ìˆ˜ë¡ ì°½ì˜ì , ë†’ì„ìˆ˜ë¡ ì •í™•í•©ë‹ˆë‹¤. ê¶Œì¥: 4-15",
                )
                num_inference_steps = gr.Slider(
                    label="ì¶”ë¡  ìŠ¤í…",
                    minimum=10,
                    maximum=50,
                    step=1,
                    value=28,
                    info="ì´ë¯¸ì§€ ìƒì„± ê³¼ì •ì˜ ë‹¨ê³„ ìˆ˜ì…ë‹ˆë‹¤. ë†’ì„ìˆ˜ë¡ í’ˆì§ˆì´ ì¢‹ì§€ë§Œ ì‹œê°„ì´ ë” ê±¸ë¦½ë‹ˆë‹¤. ê¶Œì¥: 20-28",
                )

            with gr.Row():
                seed = gr.Number(
                    label="ì‹œë“œ",
                    value=42,
                    precision=0,
                    info="ë‚œìˆ˜ ìƒì„±ì˜ ì‹œì‘ì ì…ë‹ˆë‹¤. ê°™ì€ ì‹œë“œë¥¼ ì‚¬ìš©í•˜ë©´ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤.",
                )
                strength = gr.Slider(
                    label="ê°•ë„",
                    minimum=0.1,
                    maximum=1.0,
                    step=0.1,
                    value=0.8,
                    info="ìƒì„± ëª¨ë¸ì˜ ê°•ë„ë¥¼ ì œì–´í•©ë‹ˆë‹¤. ë‚®ì„ìˆ˜ë¡ ë‹¤ì–‘í•œ ê²°ê³¼, ë†’ì„ìˆ˜ë¡ ì¼ê´€ì„± ìˆëŠ” ê²°ê³¼ì…ë‹ˆë‹¤.",
                )

            generate_btn = gr.Button("ğŸš€ ì´ë¯¸ì§€ ìƒì„±", variant="primary", size="lg")

        with gr.Column(scale=1):
            # Output
            output_image = gr.Image(label="ìƒì„±ëœ ì´ë¯¸ì§€", height=800)
            output_message = gr.Textbox(label="ìƒíƒœ", interactive=False)

    # Connect the generate button to the function
    generate_btn.click(
        fn=generate_image,
        inputs=[
            prompt,
            width,
            height,
            guidance_scale,
            num_inference_steps,
            seed,
            strength,
        ],
        outputs=[output_image, output_message],
    )

    gr.Markdown("---")
    gr.Markdown(
        """
    ### íŒŒë¼ë¯¸í„° ì„¤ëª…:
    
    **í”„ë¡¬í”„íŠ¸** (Prompt)
    - ìƒì„±í•˜ê³  ì‹¶ì€ ì´ë¯¸ì§€ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ì„¤ëª…ì…ë‹ˆë‹¤
    - ìì„¸í• ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤. ì˜ˆ: "ì—¬ì, ë¯¸ì†Œ, í•´ë³€, ë¹¨ê°„ ë¹„í‚¤ë‹ˆ"
    - 77ë‹¨ì–´ ì´í•˜ ê¶Œì¥
    
    **ì´ë¯¸ì§€ í¬ê¸°** (Width/Height)
    - ìƒì„±í•  ì´ë¯¸ì§€ì˜ ë„ˆë¹„ì™€ ë†’ì´ë¥¼ ì§€ì •í•©ë‹ˆë‹¤
    - 256-1024px ë²”ìœ„ì—ì„œ 64ì˜ ë°°ìˆ˜ë¡œ ì„¤ì •
    
    **Guidance Scale (í”„ë¡¬í”„íŠ¸ ê°•ë„)**
    - ëª¨ë¸ì´ í”„ë¡¬í”„íŠ¸ë¥¼ ì–¼ë§ˆë‚˜ ë”°ë¥¼ì§€ ì œì–´í•©ë‹ˆë‹¤
    - ë‚®ì„ìˆ˜ë¡ ì°½ì˜ì , ë†’ì„ìˆ˜ë¡ í”„ë¡¬í”„íŠ¸ì— ì •í™•í•©ë‹ˆë‹¤
    - ê¶Œì¥ê°’: 4-15
    
    **ì¶”ë¡  ìŠ¤í…** (Number of Inference Steps)
    - ì´ë¯¸ì§€ ìƒì„± ê³¼ì •ì˜ ë‹¨ê³„ ìˆ˜ì…ë‹ˆë‹¤
    - ë†’ì„ìˆ˜ë¡ í’ˆì§ˆì´ ì¢‹ì§€ë§Œ ì‹œê°„ì´ ë” ê±¸ë¦½ë‹ˆë‹¤
    - ê¶Œì¥ê°’: 20-28
    
    **ì‹œë“œ** (Seed)
    - ë‚œìˆ˜ ìƒì„±ì˜ ì‹œì‘ì ì…ë‹ˆë‹¤
    - ê°™ì€ ì‹œë“œë¥¼ ì‚¬ìš©í•˜ë©´ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤
    
    **ê°•ë„** (Strength)
    - ìƒì„± ëª¨ë¸ì˜ ê°•ë„ë¥¼ ì œì–´í•©ë‹ˆë‹¤
    - ë‚®ì„ìˆ˜ë¡ ë‹¤ì–‘í•œ ê²°ê³¼, ë†’ì„ìˆ˜ë¡ ì¼ê´€ì„± ìˆëŠ” ê²°ê³¼
    - ë²”ìœ„: 0.1-1.0
    """
    )

# Launch the interface
if __name__ == "__main__":
    interface.launch(inbrowser=True)
