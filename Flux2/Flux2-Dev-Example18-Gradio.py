import torch
from diffusers import Flux2Pipeline
from datetime import datetime
from PIL import Image
import os
import warnings
import gradio as gr
import platform
import psutil

# ======================== í•˜ë“œì›¨ì–´ ì •ë³´ ì¶œë ¥ ========================
print("\n" + "=" * 60)
print("ğŸ–¥ï¸  ì‹œìŠ¤í…œ ì •ë³´")
print("=" * 60)

# CPU ì •ë³´
cpu_count = psutil.cpu_count(logical=False)
cpu_count_logical = psutil.cpu_count(logical=True)
cpu_freq = psutil.cpu_freq().current if psutil.cpu_freq() else "ì •ë³´ ì—†ìŒ"
print(f"CPU: {platform.processor()}")
print(f"  - ì½”ì–´: {cpu_count}ê°œ (ë…¼ë¦¬ ì½”ì–´: {cpu_count_logical}ê°œ)")
print(f"  - í´ëŸ­: {cpu_freq} MHz")

# RAM ì •ë³´
ram = psutil.virtual_memory()
print(f"\në©”ëª¨ë¦¬ (RAM):")
print(f"  - ì´ ìš©ëŸ‰: {ram.total / (1024**3):.2f} GB")
print(f"  - ì‚¬ìš© ì¤‘: {ram.used / (1024**3):.2f} GB")
print(f"  - ì—¬ìœ : {ram.available / (1024**3):.2f} GB")

# GPU/CUDA ì •ë³´
print(f"\nê·¸ë˜í”½ ì¹´ë“œ (GPU):")
if torch.cuda.is_available():
    print(f"  - GPU: {torch.cuda.get_device_name(0)}")
    print(f"  - CUDA: ì‚¬ìš© ê°€ëŠ¥ (ë²„ì „: {torch.version.cuda})")
    print(
        f"  - VRAM: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.2f} GB"
    )
else:
    print(f"  - GPU: ë¯¸ì—°ê²° (CUDA ë¯¸ì§€ì›)")
    print(f"  - VRAM: N/A")

print(f"\ní˜„ì¬ ì‹¤í–‰: CPU ëª¨ë“œ (GPU VRAM ë³´ì¡° ì‚¬ìš©)")
print("=" * 60 + "\n")

# Set device and data type
device = "cpu"
dtype = torch.float32

# Load text-to-image pipeline
pipe = Flux2Pipeline.from_pretrained(
    "black-forest-labs/FLUX.2-dev", torch_dtype=dtype
).to(device)

# Enable memory optimizations - uses GPU VRAM when available
#if torch.cuda.is_available():
#    print("GPU VRAM í™œìš© ìµœì í™” í™œì„±í™” ì¤‘...")
#    pipe.enable_model_cpu_offload()  # ëª¨ë¸ ì¼ë¶€ë¥¼ GPU VRAMì— ì €ì¥í•˜ì—¬ CPU RAM ì ˆì•½
#    print(f"  â†’ CPU RAM ì ˆì•½ & GPU VRAM í™œìš© ëª¨ë“œ")
#else:
#    print("GPU ë¯¸ì—°ê²° - CPU ì „ìš© ìµœì í™” ì‚¬ìš©")
#    pipe.enable_attention_slicing(1)  # ì–´í…ì…˜ ê³„ì‚° ë©”ëª¨ë¦¬ ì ˆì•½

pipe.enable_model_cpu_offload()  # ëª¨ë¸ ì¼ë¶€ë¥¼ GPU VRAMì— ì €ì¥í•˜ì—¬ CPU RAM ì ˆì•½
pipe.enable_attention_slicing(1)  # ì–´í…ì…˜ ê³„ì‚° ë©”ëª¨ë¦¬ ì ˆì•½
# pipe.enable_sequential_cpu_offload()  # ì‹œí€€ì…œ ì˜¤í”„ë¡œë”©ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½(Don't use it with CPU offloading already enabled)
print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

prompt_input = "Highly realistic, 4k, high-quality, high resolution, beautiful korean woman model photography. She has black, medium-length hair that reaches her shoulders, tied back in a casual yet stylish manner, wearing a red bikini. Perfect anatomy. Her eyes are hazel, with a natural sparkle of happiness as she smiles. Orange hue, solid orange backdrop, using a camera setup that mimics a large aperture,f/1.4 --ar 9:16 --style raw."


def generate_image(
    prompt, width, height, guidance_scale, num_inference_steps, seed, strength
):
    try:
        # Run the pipeline
        image = pipe(
            prompt=prompt,
            width=width,
            height=height,
            guidance_scale=guidance_scale,
            num_inference_steps=num_inference_steps,
            generator=torch.Generator(device=device).manual_seed(seed),
        ).images[0]

        # Save with timestamp
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        script_name = os.path.splitext(os.path.basename(__file__))[0]
        filename = f"{script_name}_{timestamp}.png"
        image.save(filename)

        return image, f"âœ“ ì´ë¯¸ì§€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filename}"
    except Exception as e:
        return None, f"âœ— ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


# Create Gradio interface
with gr.Blocks(title="Flux.2-dev Image Generator") as interface:
    gr.Markdown("# ğŸ¨ Flux.2-dev Image Generator")
    gr.Markdown("AIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì—ì„œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

    with gr.Row():
        with gr.Column(scale=1):
            # Input parameters
            prompt = gr.Textbox(
                label="í”„ë¡¬í”„íŠ¸",
                value=prompt_input,
                lines=3,
                placeholder="ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª…ì„ ì…ë ¥í•˜ì„¸ìš” (77ë‹¨ì–´ ì´í•˜ ê¶Œì¥)",
                info="ìƒì„±í•˜ê³  ì‹¶ì€ ì´ë¯¸ì§€ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ì„¤ëª…ì…ë‹ˆë‹¤. ìì„¸í• ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤. ì˜ˆ: 'ì—¬ì, ë¯¸ì†Œ, í•´ë³€, ë¹¨ê°„ ë¹„í‚¤ë‹ˆ'",
            )

            with gr.Row():
                width = gr.Slider(
                    label="ì´ë¯¸ì§€ ë„ˆë¹„",
                    minimum=256,
                    maximum=1024,
                    step=64,
                    value=384,
                    info="CPU í™˜ê²½ì—ì„œëŠ” 384x384 ê¶Œì¥ (ë¹ ë¥¸ ìƒì„±). 64ì˜ ë°°ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.",
                )
                height = gr.Slider(
                    label="ì´ë¯¸ì§€ ë†’ì´",
                    minimum=256,
                    maximum=1024,
                    step=64,
                    value=384,
                    info="CPU í™˜ê²½ì—ì„œëŠ” 384x384 ê¶Œì¥ (ë¹ ë¥¸ ìƒì„±). 64ì˜ ë°°ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.",
                )

            with gr.Row():
                guidance_scale = gr.Slider(
                    label="Guidance Scale (í”„ë¡¬í”„íŠ¸ ê°•ë„)",
                    minimum=1.0,
                    maximum=20.0,
                    step=0.5,
                    value=4.0,
                    info="ëª¨ë¸ì´ í”„ë¡¬í”„íŠ¸ë¥¼ ì–¼ë§ˆë‚˜ ë”°ë¥¼ì§€ ì œì–´í•©ë‹ˆë‹¤. ë‚®ì„ìˆ˜ë¡ ì°½ì˜ì , ë†’ì„ìˆ˜ë¡ ì •í™•í•©ë‹ˆë‹¤. ê¶Œì¥: 4-15",
                )
                num_inference_steps = gr.Slider(
                    label="ì¶”ë¡  ìŠ¤í…",
                    minimum=10,
                    maximum=50,
                    step=1,
                    value=16,
                    info="ì´ë¯¸ì§€ ìƒì„± ê³¼ì •ì˜ ë‹¨ê³„ ìˆ˜ì…ë‹ˆë‹¤. CPUëŠ” 10-16 ê¶Œì¥ (ë¹ ë¥¸ ìƒì„±), GPUëŠ” 20-28",
                )

            with gr.Row():
                seed = gr.Number(
                    label="ì‹œë“œ",
                    value=42,
                    precision=0,
                    info="ë‚œìˆ˜ ìƒì„±ì˜ ì‹œì‘ì ì…ë‹ˆë‹¤. ê°™ì€ ì‹œë“œë¥¼ ì‚¬ìš©í•˜ë©´ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤.",
                )
                strength = gr.Slider(
                    label="ê°•ë„",
                    minimum=0.1,
                    maximum=1.0,
                    step=0.1,
                    value=0.8,
                    info="ìƒì„± ëª¨ë¸ì˜ ê°•ë„ë¥¼ ì œì–´í•©ë‹ˆë‹¤. ë‚®ì„ìˆ˜ë¡ ë‹¤ì–‘í•œ ê²°ê³¼, ë†’ì„ìˆ˜ë¡ ì¼ê´€ì„± ìˆëŠ” ê²°ê³¼ì…ë‹ˆë‹¤.",
                )

            generate_btn = gr.Button("ğŸš€ ì´ë¯¸ì§€ ìƒì„±", variant="primary", size="lg")

        with gr.Column(scale=1):
            # Output
            output_image = gr.Image(label="ìƒì„±ëœ ì´ë¯¸ì§€", height=800)
            output_message = gr.Textbox(label="ìƒíƒœ", interactive=False)

    # Connect the generate button to the function
    generate_btn.click(
        fn=generate_image,
        inputs=[
            prompt,
            width,
            height,
            guidance_scale,
            num_inference_steps,
            seed,
            strength,
        ],
        outputs=[output_image, output_message],
    )

    gr.Markdown("---")
    gr.Markdown(
        """
    ### íŒŒë¼ë¯¸í„° ì„¤ëª…:
    
    **í”„ë¡¬í”„íŠ¸** (Prompt)
    - ìƒì„±í•˜ê³  ì‹¶ì€ ì´ë¯¸ì§€ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ì„¤ëª…ì…ë‹ˆë‹¤
    - ìì„¸í• ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤. ì˜ˆ: "ì—¬ì, ë¯¸ì†Œ, í•´ë³€, ë¹¨ê°„ ë¹„í‚¤ë‹ˆ"
    - 77ë‹¨ì–´ ì´í•˜ ê¶Œì¥
    
    **ì´ë¯¸ì§€ í¬ê¸°** (Width/Height)
    - ìƒì„±í•  ì´ë¯¸ì§€ì˜ ë„ˆë¹„ì™€ ë†’ì´ë¥¼ ì§€ì •í•©ë‹ˆë‹¤
    - 256-1024px ë²”ìœ„ì—ì„œ 64ì˜ ë°°ìˆ˜ë¡œ ì„¤ì •
    
    **Guidance Scale (í”„ë¡¬í”„íŠ¸ ê°•ë„)**
    - ëª¨ë¸ì´ í”„ë¡¬í”„íŠ¸ë¥¼ ì–¼ë§ˆë‚˜ ë”°ë¥¼ì§€ ì œì–´í•©ë‹ˆë‹¤
    - ë‚®ì„ìˆ˜ë¡ ì°½ì˜ì , ë†’ì„ìˆ˜ë¡ í”„ë¡¬í”„íŠ¸ì— ì •í™•í•©ë‹ˆë‹¤
    - ê¶Œì¥ê°’: 4-15
    
    **ì¶”ë¡  ìŠ¤í…** (Number of Inference Steps)
    - ì´ë¯¸ì§€ ìƒì„± ê³¼ì •ì˜ ë‹¨ê³„ ìˆ˜ì…ë‹ˆë‹¤
    - ë†’ì„ìˆ˜ë¡ í’ˆì§ˆì´ ì¢‹ì§€ë§Œ ì‹œê°„ì´ ë” ê±¸ë¦½ë‹ˆë‹¤
    - ê¶Œì¥ê°’: 20-28
    
    **ì‹œë“œ** (Seed)
    - ë‚œìˆ˜ ìƒì„±ì˜ ì‹œì‘ì ì…ë‹ˆë‹¤
    - ê°™ì€ ì‹œë“œë¥¼ ì‚¬ìš©í•˜ë©´ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤
    
    **ê°•ë„** (Strength)
    - ìƒì„± ëª¨ë¸ì˜ ê°•ë„ë¥¼ ì œì–´í•©ë‹ˆë‹¤
    - ë‚®ì„ìˆ˜ë¡ ë‹¤ì–‘í•œ ê²°ê³¼, ë†’ì„ìˆ˜ë¡ ì¼ê´€ì„± ìˆëŠ” ê²°ê³¼
    - ë²”ìœ„: 0.1-1.0
    """
    )

# Launch the interface
if __name__ == "__main__":
    interface.launch(inbrowser=True)
