{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b980a72-489e-4a43-ad69-50e2f0729ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.autonotebook import tqdm\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "import pandas as pd\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "ds = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a16d812e-29b8-468f-b0dc-0dfc44dae760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 19\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BUF = 60000\n",
    "TEST_BUF = 10000\n",
    "BATCH_SIZE = 512\n",
    "N_TRAIN_BATCHES = int(TRAIN_BUF/BATCH_SIZE)\n",
    "N_TEST_BATCHES = int(TEST_BUF/BATCH_SIZE)\n",
    "print(N_TRAIN_BATCHES, N_TEST_BATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0698b706-136b-4607-9b47-bd4ea635d871",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20457ca5-dbac-4b40-8140-14c6b0334466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype(\"float32\")/255.0\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype(\"float32\")/255.0\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "037e13f6-d374-4d43-add7-3406655709e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None)>\n",
      "<_BatchDataset element_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None)>\n"
     ]
    }
   ],
   "source": [
    "train_dataset = (tf.data.Dataset.from_tensor_slices(train_images).shuffle(60000).batch(512))\n",
    "test_dataset = (tf.data.Dataset.from_tensor_slices(test_images).shuffle(10000).batch(512))\n",
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6def77e6-78fe-4d29-8d9f-6f396c63bfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(VAE, self).__init__()\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "        self.enc = tf.keras.Sequential(self.enc)\n",
    "        self.dec = tf.keras.Sequential(self.dec)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mu, sigma = tf.split(self.enc(x), num_or_size_splits=2, axis=1)\n",
    "        return ds.MultivariateNormalDiag(loc=mu, scale_diag=sigma)\n",
    "        \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        epsilon = tf.random.normal(shape=mean.shape)\n",
    "        return epsilon * tf.exp(logvar * 0.5) + mean\n",
    "\n",
    "    def reconstruct(self, x):\n",
    "        mu, _ = tf.split(self.enc(x), num_or_size_splits=2, axis=1)\n",
    "        return self.decode(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.dec(z)\n",
    "\n",
    "    def loss_function(self, x):\n",
    "        q_z = self.encode(x)\n",
    "        z = q_z.sample()\n",
    "        x_recon = self.decode(z)\n",
    "        p_z = ds.MultivariateNormalDiag(\n",
    "          loc=[0.] * z.shape[-1], scale_diag=[1.] * z.shape[-1]\n",
    "          )\n",
    "        kl_div = ds.kl_divergence(q_z, p_z)\n",
    "        latent_loss = tf.reduce_mean(tf.maximum(kl_div, 0))\n",
    "        recon_loss = tf.reduce_mean(tf.reduce_sum(tf.math.square(x - x_recon), axis=0))\n",
    "        return recon_loss, latent_loss\n",
    "\n",
    "    def gradients(self, x):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self.loss_function(x)\n",
    "        return tape.gradient(loss, self.trainable_variables)\n",
    "\n",
    "    @tf.function\n",
    "    def train(self, train_x):\n",
    "        gradients = self.gradients(train_x)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "42646fb2-c4f7-4324-919b-39aa3c733cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = [ \n",
    "    tf.keras.layers.InputLayer(shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation=\"relu\"), \n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation=\"relu\"),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=2*2),\n",
    "]\n",
    "\n",
    "decoder = [\n",
    "    tf.keras.layers.Dense(units=7*7*64, activation=\"relu\"),\n",
    "    tf.keras.layers.Reshape(target_shape=(7, 7, 64)),\n",
    "    tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\", activation=\"sigmoid\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6ccf3f2c-8607-4b5c-8d65-525a8fd10f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(\n",
    "    enc = encoder,\n",
    "    dec = decoder,\n",
    "    optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "18511a20-0ec7-4718-a453-3be2d7c873ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"vae_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"vae_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">28,036</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential_8 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │        \u001b[38;5;34m28,036\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_9 (\u001b[38;5;33mSequential\u001b[0m)       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,036</span> (109.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,036\u001b[0m (109.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,036</span> (109.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m28,036\u001b[0m (109.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "58b50ef4-5a1e-4a6d-9a70-3574c31534dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = next(iter(test_dataset))\n",
    "\n",
    "def plot_reconstruction(model, example_data, nex=8, zm=2):\n",
    "\n",
    "    example_data_reconstructed = model.reconstruct(example_data)\n",
    "    samples = model.decode(tf.random.normal(shape=(BATCH_SIZE, 2)))\n",
    "    fig, axs = plt.subplots(ncols=nex, nrows=3, figsize=(zm * nex, zm * 3))\n",
    "    for axi, (dat, lab) in enumerate(\n",
    "        zip(\n",
    "            [example_data, example_data_reconstructed, samples],\n",
    "            [\"data\", \"data recon\", \"samples\"],\n",
    "        )\n",
    "    ):\n",
    "        for ex in range(nex):\n",
    "            axs[axi, ex].matshow(\n",
    "                dat.numpy()[ex].squeeze(), cmap=plt.cm.Greys, vmin=0, vmax=1\n",
    "            )\n",
    "            axs[axi, ex].axes.get_xaxis().set_ticks([])\n",
    "            axs[axi, ex].axes.get_yaxis().set_ticks([])\n",
    "        axs[axi, 0].set_ylabel(lab)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7ff77e21-c3a6-4c61-a7e6-737a273d4fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(columns = ['recon_loss', 'latent_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4409698e-fe0a-429a-a2fb-0ea69a589724",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for batch, train_x in tqdm(\n",
    "        zip(range(N_TRAIN_BATCHES), train_dataset), total=N_TRAIN_BATCHES):\n",
    "        model.train(train_x)\n",
    "        loss = []\n",
    "        \n",
    "    for batch, test_x in tqdm(\n",
    "        zip(range(N_TEST_BATCHES), test_dataset), total=N_TEST_BATCHES): \n",
    "        loss.append(model.loss_function(train_x))\n",
    "    losses.loc[len(losses)] = np.mean(loss, axis=0) \n",
    "    display.clear_output()\n",
    "    print(\n",
    "        \"Epoch: {} | recon_loss: {} | latent_loss: {}\".format(\n",
    "            epoch, losses.recon_loss.values[-1], losses.latent_loss.values[-1]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plot_reconstruction(model, example_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1e78f6-b1ab-4430-9a64-277775b69912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
