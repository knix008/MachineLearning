{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uCKXuvPHHjv2"
   },
   "source": [
    "# Unpaired Style Transfer using CycleGAN\n",
    "[CycleGAN](https://arxiv.org/pdf/1703.10593.pdf) improves upon paired style transfer architecture by relaxing the constraint on input and output images. CycleGAN explores the unpaired style transfer paradigm where the model actually tries to learn the stylistic differences between source and target domains without explicit pairing between input and output images. Zhu and Park et al. describe this unpaired style transfer similar to our ability of imagining how a Van Gogh or Monet would have painted a particular scene (without having actually seen a side by side example). Quoting from the paper  itself,\n",
    "\n",
    "> Instead, we have knowledge of the set of Monet paintings and of the set of landscape photographs. We can reason about the stylistic differences between these two sets, and thereby imagine what a scene might look like if we were to “translate” it from one set into the other.\n",
    "\n",
    "\n",
    "This provides a nice advantage as well as opens additional use cases where exact pairing of source and target domains is either not available or we do not have enough training examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PacktPublishing/Hands-On-Generative-AI-with-Python-and-TensorFlow-2/blob/master/Chapter_7/cycleGAN/cycleGAN.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "96KODlRlHw_U"
   },
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dPiwLNeuHTHs"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Concatenate\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mf4p-sC9Hzvo"
   },
   "source": [
    "## Load Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BbYojuCFH2HA"
   },
   "outputs": [],
   "source": [
    "from gan_utils import downsample_block, upsample_block, discriminator_block\n",
    "from data_utils import plot_sample_images, batch_generator, get_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "34-1KnuoIJIZ"
   },
   "source": [
    "## Set Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QrO-1txCIKaG"
   },
   "outputs": [],
   "source": [
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (8,8),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v6VJVut1IOb1"
   },
   "outputs": [],
   "source": [
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "dataset_name = 'apple2orange'\n",
    "\n",
    "DOWNLOAD_URL = 'https://efrosgans.eecs.berkeley.edu/cyclegan/datasets/{}.zip'.format(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MNlB3DLfIdos"
   },
   "source": [
    "## U-Net Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XtoXEh5yIczr"
   },
   "outputs": [],
   "source": [
    "def build_generator(img_shape, channels=3, num_filters=32):\n",
    "    # Image input\n",
    "    input_layer = Input(shape=img_shape)\n",
    "\n",
    "    # Downsampling\n",
    "    down_sample_1 = downsample_block(input_layer, num_filters)\n",
    "    down_sample_2 = downsample_block(down_sample_1, num_filters*2)\n",
    "    down_sample_3 = downsample_block(down_sample_2,num_filters*4)\n",
    "    down_sample_4 = downsample_block(down_sample_3,num_filters*8)\n",
    "\n",
    "    # Upsampling\n",
    "    upsample_1 = upsample_block(down_sample_4, down_sample_3, num_filters*4)\n",
    "    upsample_2 = upsample_block(upsample_1, down_sample_2, num_filters*2)\n",
    "    upsample_3 = upsample_block(upsample_2, down_sample_1, num_filters)\n",
    "\n",
    "    upsample_4 = UpSampling2D(size=2)(upsample_3)\n",
    "    output_img = Conv2D(channels, \n",
    "                        kernel_size=4, \n",
    "                        strides=1, \n",
    "                        padding='same', \n",
    "                        activation='tanh')(upsample_4)\n",
    "\n",
    "    return Model(input_layer, output_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxqdxDl9KCNZ"
   },
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CWrb6eltKEI7"
   },
   "outputs": [],
   "source": [
    "def build_discriminator(img_shape,num_filters=64):\n",
    "    input_layer = Input(shape=img_shape)\n",
    "\n",
    "    disc_block_1 = discriminator_block(input_layer, \n",
    "                                       num_filters, \n",
    "                                       instance_normalization=False)\n",
    "    disc_block_2 = discriminator_block(disc_block_1, num_filters*2)\n",
    "    disc_block_3 = discriminator_block(disc_block_2, num_filters*4)\n",
    "    disc_block_4 = discriminator_block(disc_block_3, num_filters*8)\n",
    "\n",
    "    output = Conv2D(1, kernel_size=4, strides=1, padding='same')(disc_block_4)\n",
    "\n",
    "    return Model(input_layer, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p0Nh4KPwOmtG"
   },
   "source": [
    "## GAN Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OpGBbQVbOqk6"
   },
   "outputs": [],
   "source": [
    "generator_filters = 32\n",
    "discriminator_filters = 64\n",
    "\n",
    "# input shape\n",
    "channels = 3\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, channels)\n",
    "\n",
    "# Loss weights\n",
    "lambda_cycle = 10.0            \n",
    "lambda_identity = 0.1 * lambda_cycle\n",
    "\n",
    "optimizer = Adam(0.0002, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-mxiZNLXPDPL",
    "outputId": "b7ad91a0-4035-4395-9011-a6de2650583e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch Shape=(8, 8, 1)\n"
     ]
    }
   ],
   "source": [
    "# prepare patch size for our setup\n",
    "patch = int(IMG_HEIGHT / 2**4)\n",
    "patch_gan_shape = (patch, patch, 1)\n",
    "print(\"Patch Shape={}\".format(patch_gan_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ducn929OeHS"
   },
   "source": [
    "## Get Discriminators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nh6abq-FOh2w"
   },
   "outputs": [],
   "source": [
    "disc_A = build_discriminator(input_shape,discriminator_filters)\n",
    "disc_A.compile(loss='mse',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "disc_B = build_discriminator(input_shape,discriminator_filters)\n",
    "disc_B.compile(loss='mse',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c1xbfgwaPva5"
   },
   "source": [
    "## Get Generators and GAN Model Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O6eshkmgPxJb"
   },
   "outputs": [],
   "source": [
    "gen_AB = build_generator(input_shape, channels, generator_filters)\n",
    "gen_BA = build_generator(input_shape, channels, generator_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UYSnhHIBQRmx"
   },
   "outputs": [],
   "source": [
    "img_A = Input(shape=input_shape)\n",
    "img_B = Input(shape=input_shape)\n",
    "\n",
    "# generate fake samples from both generators\n",
    "fake_B = gen_AB(img_A)\n",
    "fake_A = gen_BA(img_B)\n",
    "\n",
    "# reconstruct orginal samples from both generators\n",
    "reconstruct_A = gen_BA(fake_B)\n",
    "reconstruct_B = gen_AB(fake_A)\n",
    "\n",
    "# generate identity samples\n",
    "identity_A = gen_BA(img_A)\n",
    "identity_B = gen_AB(img_B)\n",
    "\n",
    "# disable discriminator training\n",
    "disc_A.trainable = False\n",
    "disc_B.trainable = False\n",
    "\n",
    "# use discriminator to classify real vs fake\n",
    "output_A = disc_A(fake_A)\n",
    "output_B = disc_B(fake_B)\n",
    "\n",
    "# Combined model trains generators to fool discriminators\n",
    "gan = Model(inputs=[img_A, img_B],\n",
    "            outputs=[output_A, output_B,\n",
    "                     reconstruct_A, reconstruct_B,\n",
    "                     identity_A, identity_B ])\n",
    "gan.compile(loss=['mse', 'mse','mae', 'mae','mae', 'mae'],\n",
    "            loss_weights=[1, 1,\n",
    "                          lambda_cycle, lambda_cycle,\n",
    "                          lambda_identity, lambda_identity ],\n",
    "            optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PFeKVfhyK40c"
   },
   "source": [
    "## Custom Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZfcV4UsK6Tv"
   },
   "outputs": [],
   "source": [
    "def train(gen_AB, \n",
    "          gen_BA, \n",
    "          disc_A, \n",
    "          disc_B, \n",
    "          gan, \n",
    "          patch_gan_shape, \n",
    "          epochs, \n",
    "          path='./content/{}'.format(dataset_name) ,\n",
    "          batch_size=1, \n",
    "          sample_interval=50):\n",
    "\n",
    "    # Adversarial loss ground truths\n",
    "    real_y = np.ones((batch_size,) + patch_gan_shape)\n",
    "    fake_y = np.zeros((batch_size,) + patch_gan_shape)\n",
    "\n",
    "    imgs = batch_generator(path, batch_size, image_res=[IMG_HEIGHT, IMG_WIDTH])\n",
    "    print(imgs)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch={}\".format(epoch))\n",
    "        for idx, (imgs_A, imgs_B) in enumerate(batch_generator(path,\n",
    "                                                               batch_size,\n",
    "                                                               image_res=[IMG_HEIGHT, IMG_WIDTH])):\n",
    "\n",
    "            # train discriminators\n",
    "\n",
    "            # generate fake samples from both generators\n",
    "            fake_B = gen_AB.predict(imgs_A)\n",
    "            fake_A = gen_BA.predict(imgs_B)\n",
    "\n",
    "            # Train the discriminators (original images = real / translated = Fake)\n",
    "            disc_A_loss_real = disc_A.train_on_batch(imgs_A, real_y)\n",
    "            disc_A_loss_fake = disc_A.train_on_batch(fake_A, fake_y)\n",
    "            disc_A_loss = 0.5 * np.add(disc_A_loss_real, disc_A_loss_fake)\n",
    "\n",
    "            disc_B_loss_real = disc_B.train_on_batch(imgs_B, real_y)\n",
    "            disc_B_loss_fake = disc_B.train_on_batch(fake_B, fake_y)\n",
    "            disc_B_loss = 0.5 * np.add(disc_B_loss_real, disc_B_loss_fake)\n",
    "\n",
    "            # Total disciminator loss\n",
    "            discriminator_loss = 0.5 * np.add(disc_A_loss, disc_B_loss)\n",
    "\n",
    "\n",
    "            # train generator\n",
    "            gen_loss = gan.train_on_batch([imgs_A, imgs_B],\n",
    "                                          [\n",
    "                                           real_y, real_y,\n",
    "                                           imgs_A, imgs_B,\n",
    "                                           imgs_A, imgs_B\n",
    "                                           ]\n",
    "                                          )\n",
    "\n",
    "            # training updates every 50 iterations\n",
    "            if idx % 50 == 0:\n",
    "              print (\"[Epoch {}/{}] [Discriminator loss: {}, accuracy: {}][Generator loss: {}, Adversarial Loss: {}, Reconstruction Loss: {}, Identity Loss: {}]\".format(idx, \n",
    "                                                  epoch,\n",
    "                                                  discriminator_loss[0], \n",
    "                                                  100*discriminator_loss[1],\n",
    "                                                  gen_loss[0],\n",
    "                                                  np.mean(gen_loss[1:3]),\n",
    "                                                  np.mean(gen_loss[3:5]),\n",
    "                                                  np.mean(gen_loss[5:6])))\n",
    "              \n",
    "            # Plot and Save progress every few iterations\n",
    "            if idx % sample_interval == 0:\n",
    "              plot_sample_images(gen_AB,\n",
    "                                 gen_BA,\n",
    "                                 path=path,\n",
    "                                 epoch=epoch,\n",
    "                                 batch_num=idx,\n",
    "                                 output_dir='images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GjVtbMbfRni0"
   },
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4OOhkZJ_RpDm",
    "outputId": "37d6755d-3b40-4444-bf46-7644dadeb204"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://efrosgans.eecs.berkeley.edu/cyclegan/datasets/apple2orange.zip\n",
      "78462976/78456409 [==============================] - 9s 0us/step\n",
      "78471168/78456409 [==============================] - 9s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'D:\\\\Home\\\\Project\\\\MachineLearning\\\\GAN\\\\gan_utils\\\\content\\\\apple2orange.tar.gz'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "path = os.path.join(path, 'content')\n",
    "\n",
    "tf.keras.utils.get_file('{}.tar.gz'.format(dataset_name),\n",
    "                         origin=DOWNLOAD_URL,\n",
    "                         cache_subdir=path,\n",
    "                         extract=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bsoIw2mvR0jv"
   },
   "source": [
    "## Training Begins!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ucqAk1E8R2eB",
    "outputId": "338589aa-9c44-4c4f-91ef-8e1f7cd533c4"
   },
   "outputs": [],
   "source": [
    "train(gen_AB, \n",
    "      gen_BA, \n",
    "      disc_A, \n",
    "      disc_B, \n",
    "      gan, \n",
    "      patch_gan_shape, \n",
    "      epochs=200, \n",
    "      batch_size=1, \n",
    "      sample_interval=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of the program"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cycleGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
