import gradio as gr
import torch
from diffusers import StableDiffusion3ControlNetPipeline, SD3ControlNetModel
import cv2
import numpy as np
from PIL import Image
import os


# Stable Diffusion 3.5 ëª¨ë¸ ë° íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
def initialize_models():
    """Stable Diffusion 3.5 Largeì™€ ControlNet íŒŒì´í”„ë¼ì¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    try:
        # SD3 ControlNet ëª¨ë¸ ë¡œë“œ (Canny)
        controlnet = SD3ControlNetModel.from_pretrained(
            "InstantX/SD3-Controlnet-Canny", torch_dtype=torch.float32
        )

        # Stable Diffusion 3.5 Large + ControlNet íŒŒì´í”„ë¼ì¸ ë¡œë“œ
        pipe = StableDiffusion3ControlNetPipeline.from_pretrained(
            "stabilityai/stable-diffusion-3.5-large",
            controlnet=controlnet,
            torch_dtype=torch.float32,
        )

        pipe.enable_model_cpu_offload()
        pipe = pipe.to("cpu")
        print("Model loaded successfully.")
    except Exception as e:
        print(f"ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        print("Hugging Face Hubì— ë¡œê·¸ì¸í–ˆê³  ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        pipe = None
    return pipe


# Canny edge detection ì „ì²˜ë¦¬
def preprocess_canny(image, low_threshold=100, high_threshold=200):
    """ì…ë ¥ ì´ë¯¸ì§€ì— Canny edge detectionì„ ì ìš©í•©ë‹ˆë‹¤."""
    # PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜
    image_np = np.array(image)

    # RGBë¥¼ Grayscaleë¡œ ë³€í™˜
    if len(image_np.shape) == 3:
        gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
    else:
        gray = image_np

    # Canny edge detection ì ìš©
    canny = cv2.Canny(gray, low_threshold, high_threshold)

    # 3ì±„ë„ë¡œ ë³€í™˜ (RGB)
    canny_image = cv2.cvtColor(canny, cv2.COLOR_GRAY2RGB)

    return Image.fromarray(canny_image)


# ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ (SD3.5 ControlNet ì‚¬ìš©)
def generate_image(
    input_image,
    prompt,
    negative_prompt="",
    num_inference_steps=28,
    guidance_scale=7.0,
    controlnet_conditioning_scale=1.0,
    low_threshold=100,
    high_threshold=200,
):
    """Stable Diffusion 3.5 ControlNetì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        if input_image is None:
            return None, "ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."

        if pipe is None:
            return None, "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª¨ë¸ì„ ë‹¤ì‹œ ë¡œë“œí•´ì£¼ì„¸ìš”."

        # Canny edge detection ì ìš©
        control_image = preprocess_canny(
            input_image, int(low_threshold), int(high_threshold)
        )

        # ì´ë¯¸ì§€ ìƒì„± (ControlNet ì‚¬ìš©)
        with torch.no_grad():
            result = pipe(
                prompt=prompt,
                negative_prompt=negative_prompt,
                control_image=control_image,
                num_inference_steps=int(num_inference_steps),
                guidance_scale=float(guidance_scale),
                controlnet_conditioning_scale=float(controlnet_conditioning_scale),
                height=1024,
                width=1024,
            )

        generated_image = result.images[0]
        return generated_image, "ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!"

    except Exception as e:
        return None, f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


# ëª¨ë¸ ì´ˆê¸°í™”
print("Stable Diffusion 3.5 Large + ControlNet ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘...")
pipe = initialize_models()


# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±
def create_interface():
    """Gradio ì¸í„°í˜ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""

    with gr.Blocks(
        title="SD 3.5 Large + ControlNet Generator", theme=gr.themes.Soft()
    ) as demo:
        gr.Markdown(
            """
            # ğŸ¨ Stable Diffusion 3.5 Large + ControlNet ì´ë¯¸ì§€ ìƒì„±ê¸°
            
            Stable Diffusion 3.5 Largeì™€ ControlNetì„ ì‚¬ìš©í•˜ì—¬ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
            ì…ë ¥ ì´ë¯¸ì§€ì˜ Canny edgeë¥¼ ì •í™•í•˜ê²Œ ë”°ë¼í•˜ë©° ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            """
        )

        with gr.Row():
            with gr.Column(scale=1):
                # ì…ë ¥ ì„¹ì…˜
                gr.Markdown("### ğŸ“¥ ì…ë ¥")
                input_image = gr.Image(label="ì…ë ¥ ì´ë¯¸ì§€", type="pil", height=300)

                prompt = gr.Textbox(
                    label="í”„ë¡¬í”„íŠ¸",
                    value="photorealistic, ultra high definition, ultra high resolution,8k resolution, ultra detail, vibrant colors, cinematic lighting, realistic shadows, high quality, masterpiece, best quality, perfect anatomy, good hair, good fingers, good legs",
                    lines=4,
                )

                negative_prompt = gr.Textbox(
                    label="ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ (ì„ íƒì‚¬í•­)",
                    value="blurring, low quality, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username",
                    lines=4,
                )

                # ê³ ê¸‰ ì„¤ì •
                with gr.Accordion("ğŸ”§ ê³ ê¸‰ ì„¤ì •", open=False):
                    num_inference_steps = gr.Slider(
                        minimum=20, maximum=50, value=28, step=1, label="ì¶”ë¡  ë‹¨ê³„ ìˆ˜"
                    )

                    guidance_scale = gr.Slider(
                        minimum=1.0,
                        maximum=15.0,
                        value=7.0,
                        step=0.5,
                        label="ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼",
                    )

                    controlnet_conditioning_scale = gr.Slider(
                        minimum=0.0,
                        maximum=2.0,
                        value=1.0,
                        step=0.1,
                        label="ControlNet ì»¨ë””ì…”ë‹ ìŠ¤ì¼€ì¼",
                        visible=True,
                    )

                    with gr.Row():
                        low_threshold = gr.Slider(
                            minimum=50,
                            maximum=150,
                            value=100,
                            step=10,
                            label="Canny ë‚®ì€ ì„ê³„ê°’",
                        )

                        high_threshold = gr.Slider(
                            minimum=150,
                            maximum=300,
                            value=200,
                            step=10,
                            label="Canny ë†’ì€ ì„ê³„ê°’",
                        )

                generate_btn = gr.Button("ğŸ¨ ì´ë¯¸ì§€ ìƒì„±", variant="primary", size="lg")

            with gr.Column(scale=1):
                # ì¶œë ¥ ì„¹ì…˜
                gr.Markdown("### ğŸ“¤ ì¶œë ¥")

                with gr.Row():
                    with gr.Column():
                        gr.Markdown("#### Canny Edge ê²°ê³¼")
                        canny_output = gr.Image(label="Canny Edge", height=250)

                    with gr.Column():
                        gr.Markdown("#### ìƒì„±ëœ ì´ë¯¸ì§€")
                        output_image = gr.Image(label="ìƒì„± ê²°ê³¼", height=250)

                status_text = gr.Textbox(label="ìƒíƒœ", interactive=False, lines=2)

        # ì˜ˆì‹œ í”„ë¡¬í”„íŠ¸
        with gr.Row():
            gr.Markdown("### ğŸ–¼ï¸ ì˜ˆì‹œ í”„ë¡¬í”„íŠ¸")
            sample_prompts = [
                "a photorealistic portrait of a person",
                "a modern architectural building",
                "a beautiful landscape with mountains",
                "a cute cartoon character",
            ]

            for i, prompt_text in enumerate(sample_prompts):
                gr.Button(f"ì˜ˆì‹œ {i+1}: {prompt_text[:30]}...", size="sm").click(
                    lambda p=prompt_text: p, outputs=[prompt]
                )

        # Canny edge ë¯¸ë¦¬ë³´ê¸° í•¨ìˆ˜
        def preview_canny(image, low_thresh, high_thresh):
            if image is None:
                return None
            return preprocess_canny(image, int(low_thresh), int(high_thresh))

        # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        def generate_with_canny_preview(*args):
            (
                input_img,
                prompt_text,
                neg_prompt,
                steps,
                guid_scale,
                ctrl_scale,
                low_thresh,
                high_thresh,
            ) = args

            # Canny edge ë¯¸ë¦¬ë³´ê¸° ìƒì„±
            canny_preview = None
            if input_img is not None:
                canny_preview = preprocess_canny(
                    input_img, int(low_thresh), int(high_thresh)
                )

            # ì´ë¯¸ì§€ ìƒì„±
            generated_img, status = generate_image(*args)

            return canny_preview, generated_img, status

        # ì„ê³„ê°’ ë³€ê²½ ì‹œ Canny ë¯¸ë¦¬ë³´ê¸° ì—…ë°ì´íŠ¸
        for component in [input_image, low_threshold, high_threshold]:
            component.change(
                fn=preview_canny,
                inputs=[input_image, low_threshold, high_threshold],
                outputs=[canny_output],
            )

        # ìƒì„± ë²„íŠ¼ í´ë¦­ ì´ë²¤íŠ¸
        generate_btn.click(
            fn=generate_with_canny_preview,
            inputs=[
                input_image,
                prompt,
                negative_prompt,
                num_inference_steps,
                guidance_scale,
                controlnet_conditioning_scale,
                low_threshold,
                high_threshold,
            ],
            outputs=[canny_output, output_image, status_text],
        )

    return demo


# ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰
if __name__ == "__main__":
    demo = create_interface()
    # ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰
    demo.launch(
        share=False, inbrowser=True  # ê³µìœ  ë§í¬ ìƒì„± ì—¬ë¶€  # ë¸Œë¼ìš°ì € ìë™ ì—´ê¸°
    )
