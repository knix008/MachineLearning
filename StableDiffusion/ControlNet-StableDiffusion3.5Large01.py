import torch
from diffusers import StableDiffusion3ControlNetPipeline, SD3ControlNetModel
from diffusers.utils import load_image
import cv2
import numpy as np
from PIL import Image

# 1. ì œì–´ ì´ë¯¸ì§€ ì¤€ë¹„ (Canny Edge ì¶”ì¶œ) ğŸ–¼ï¸
# ì œì–´ë¡œ ì‚¬ìš©í•  ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
url = (
    "https://huggingface.co/lllyasviel/sd-controlnet-canny/resolve/main/images/bird.png"
)
original_image = load_image(url)

# OpenCVë¥¼ ì‚¬ìš©í•˜ì—¬ Canny Edgeë¥¼ ê²€ì¶œí•©ë‹ˆë‹¤.
image_np = np.array(original_image)
canny_image = cv2.Canny(image_np, 100, 200)
canny_image = canny_image[:, :, None]
canny_image = np.concatenate([canny_image, canny_image, canny_image], axis=2)
control_image = Image.fromarray(canny_image)

# 2. ëª¨ë¸ ë¡œë”© ğŸ§ 
# ì‚¬ìš©í•  ControlNet ëª¨ë¸ê³¼ Stable Diffusion 3.5 ë² ì´ìŠ¤ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
# 'canny' ì™¸ì— 'depth', 'pose' ë“± ë‹¤ë¥¸ ControlNetì„ ì‚¬ìš©í•˜ë ¤ë©´ ëª¨ë¸ ê²½ë¡œë¥¼ ë³€ê²½í•˜ë©´ ë©ë‹ˆë‹¤.
controlnet = SD3ControlNetModel.from_pretrained(
    "stabilityai/stable-diffusion-3.5-large-controlnet-canny", torch_dtype=torch.float16
)
pipe = StableDiffusion3ControlNetPipeline.from_pretrained(
    "stabilityai/stable-diffusion-3.5-large",
    controlnet=controlnet,
    torch_dtype=torch.float16,
)

# GPU (CUDA)ë¡œ ëª¨ë¸ì„ ì´ë™ì‹œì¼œ ì—°ì‚° ì†ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.
pipe.to("cuda")

# 3. ì´ë¯¸ì§€ ìƒì„± ğŸ¨
# í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
prompt = """A beautiful photo of a majestic parrot on a branch, 
photorealistic, ultra high definition, 8k resolution, ultra detail, 
vibrant colors, cinematic lighting, realistic shadows, high quality, 
masterpiece, best quality, perfect anatomy"""

# ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ (ìƒì„±í•˜ì§€ ì•Šì„ ìš”ì†Œë“¤)
negative_prompt = """blurry, low quality, bad anatomy, bad hands, text, error, 
missing fingers, extra digit, fewer digits, cropped, worst quality, 
low quality, normal quality, jpeg artifacts, signature, watermark, 
username, deformed, distorted, disfigured, mutation, mutated"""

# íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
# control_imageê°€ êµ¬ì¡°ë¥¼, promptê°€ ë‚´ìš©ì„ ê²°ì •í•©ë‹ˆë‹¤.
generated_image = pipe(
    prompt,
    negative_prompt=negative_prompt,
    control_image=control_image,
    num_inference_steps=25,
    guidance_scale=7.5,
    controlnet_conditioning_scale=1.0,
).images[0]

# 4. ê²°ê³¼ ì €ì¥ ğŸ’¾
generated_image.save("parrot_generated_with_canny_control.png")
print("ì´ë¯¸ì§€ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤: parrot_generated_with_canny_control.png")
