import torch
import gradio as gr
from diffusers import StableDiffusionXLImg2ImgPipeline
from PIL import Image
import datetime
import os

# ëª¨ë¸ ë¡œë”© (í•œ ë²ˆë§Œ ì‹¤í–‰)
print("ëª¨ë¸ ë¡œë”© ì¤‘...")
pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-refiner-1.0",
    torch_dtype=torch.float16,
    variant="fp16",
    use_safetensors=True,
)

if torch.cuda.is_available():
    pipe = pipe.to("cuda")
else:
    print("CUDAê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤!!!");
    exit(1)
    
print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")


def resize_image_to_sdxl(image):
    """ì´ë¯¸ì§€ì˜ ë¹„ìœ¨ì€ ìœ ì§€í•˜ë©´ì„œ, ê°€ë¡œ/ì„¸ë¡œê°€ 16ì˜ ë°°ìˆ˜ë¡œë§Œ ë§ì¶¤"""
    width, height = image.size

    def round_to_16(x):
        return max(16, (x // 16) * 16)

    new_width = round_to_16(width)
    new_height = round_to_16(height)

    # í¬ê¸°ê°€ ë³€ê²½ë˜ë©´ ë¦¬ì‚¬ì´ì¦ˆ, ì•„ë‹ˆë©´ ì›ë³¸ ë°˜í™˜
    if new_width != width or new_height != height:
        return image.resize((new_width, new_height), Image.Resampling.LANCZOS)
    return image


def generate_image(input_image, prompt, negative_prompt, strength, guidance_scale, num_inference_steps, progress=gr.Progress()):
    if input_image is None:
        return None, "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
    
    if not prompt.strip():
        return None, "Promptë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    try:
        progress(0, desc="ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘...")
        
        # PIL Imageë¡œ ë³€í™˜
        if isinstance(input_image, str):
            init_image = Image.open(input_image).convert("RGB")
        else:
            init_image = input_image.convert("RGB")
        
        # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° ì •ë³´
        original_width, original_height = init_image.size
        original_aspect_ratio = original_width / original_height
        
        progress(0.1, desc="ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • ì¤‘...")
        
        # ì´ë¯¸ì§€ë¥¼ SDXLì— ì í•©í•œ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        resized_image = resize_image_to_sdxl(init_image)
        new_width, new_height = resized_image.size
        
        # í¬ê¸° ë³€ê²½ ì—¬ë¶€ í™•ì¸
        size_changed = (new_width != original_width or new_height != original_height)
        size_info = f"í¬ê¸° ìœ ì§€: {new_width}x{new_height}" if not size_changed else f"í¬ê¸° ì¡°ì •: {original_width}x{original_height} â†’ {new_width}x{new_height}"
        
        progress(0.3, desc=f"ì´ë¯¸ì§€ ìƒì„± ì¤‘... ({size_info})")
        
        # ì´ë¯¸ì§€ ìƒì„±
        result = pipe(
            prompt=prompt,
            negative_prompt=negative_prompt,
            image=resized_image,
            strength=strength,
            guidance_scale=guidance_scale,
            num_inference_steps=num_inference_steps,
            width=new_width,
            height=new_height
        )
        
        progress(0.9, desc="ì´ë¯¸ì§€ ì €ì¥ ì¤‘...")
        
        generated_image = result.images[0]
        
        # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        output_filename = f"sdxl_refined_{timestamp}.png"
        output_path = os.path.join(os.getcwd(), output_filename)
        generated_image.save(output_path)
        
        progress(1.0, desc="ì™„ë£Œ!")
        
        # í¬ê¸° ë³€ê²½ ì—¬ë¶€ì— ë”°ë¥¸ ë©”ì‹œì§€
        size_change_msg = "í¬ê¸° ìœ ì§€ë¨" if not size_changed else f"í¬ê¸° ì¡°ì •ë¨ ({original_width}x{original_height} â†’ {new_width}x{new_height})"
        
        status_message = f"""ì´ë¯¸ì§€ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!
ì €ì¥ ìœ„ì¹˜: {output_filename}
ì›ë³¸ í¬ê¸°: {original_width}x{original_height}
ìƒì„± í¬ê¸°: {new_width}x{new_height}
ì²˜ë¦¬ ê²°ê³¼: {size_change_msg}
ë¹„ìœ¨: {original_aspect_ratio:.2f}:1"""
        
        return generated_image, status_message
        
    except Exception as e:
        return None, f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±
with gr.Blocks(title="Stable Diffusion XL Refiner", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ¨ Stable Diffusion XL Refiner")
    gr.Markdown("ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê³  í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì—¬ ê³ í’ˆì§ˆì˜ ì •ì œëœ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
    
    with gr.Row():
        with gr.Column(scale=1):
            # ì…ë ¥ ì»¨íŠ¸ë¡¤
            input_image = gr.Image(
                label="ì…ë ¥ ì´ë¯¸ì§€",
                type="pil",
                height=500
            )
            
            prompt = gr.Textbox(
                label="Prompt (í”„ë¡¬í”„íŠ¸)",
                placeholder="ì˜ˆ: blue bikini, ultra high definition photo realistic portrait, similar to a photo",
                lines=3,
                value="ultra high definition photo realistic portrait, professional photography, ultra detail, similar to a photo, no deformed"
            )
            
            negative_prompt = gr.Textbox(
                label="Negative Prompt (ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸)",
                placeholder="ì˜ˆ: blurry, low quality, distorted, ugly",
                lines=2,
                value="blurry, low quality, distorted, ugly, deformed, bad anatomy"
            )
            
            with gr.Accordion("ê³ ê¸‰ ì„¤ì •", open=False):
                strength = gr.Slider(
                    label="Strength (ë³€í˜• ê°•ë„)",
                    minimum=0.1,
                    maximum=1.0,
                    value=0.8,
                    step=0.05,
                    info="ë†’ì„ìˆ˜ë¡ ì›ë³¸ì—ì„œ ë” ë§ì´ ë³€í˜•ë©ë‹ˆë‹¤"
                )
                
                guidance_scale = gr.Slider(
                    label="Guidance Scale",
                    minimum=1.0,
                    maximum=20.0,
                    value=7.5,
                    step=0.5,
                    info="í”„ë¡¬í”„íŠ¸ ì¤€ìˆ˜ ì •ë„"
                )
                
                num_inference_steps = gr.Slider(
                    label="Inference Steps",
                    minimum=10,
                    maximum=50,
                    value=20,
                    step=5,
                    info="ìƒì„± ë‹¨ê³„ ìˆ˜ (ë†’ì„ìˆ˜ë¡ í’ˆì§ˆ í–¥ìƒ, ì‹œê°„ ì¦ê°€)"
                )
            
            generate_btn = gr.Button("ğŸ¨ ì´ë¯¸ì§€ ìƒì„±", variant="primary", size="lg")
            
        with gr.Column(scale=1):
            # ì¶œë ¥ ê²°ê³¼
            output_image = gr.Image(
                label="ìƒì„±ëœ ì´ë¯¸ì§€",
                height=400
            )
            
            status_text = gr.Textbox(
                label="ìƒíƒœ",
                value="ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê³  'ì´ë¯¸ì§€ ìƒì„±' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.",
                interactive=False,
                lines=3
            )
    
    # ì˜ˆì‹œ ì´ë¯¸ì§€ì™€ í”„ë¡¬í”„íŠ¸
    gr.Markdown("## ğŸ“ ì‚¬ìš© íŒ")
    gr.Markdown("""
    - **ì´ë¯¸ì§€ í¬ê¸°**: ì›ë³¸ í¬ê¸°ë¥¼ ìµœëŒ€í•œ ìœ ì§€í•˜ë©°, 1024pxë¥¼ ì´ˆê³¼í•˜ëŠ” ê²½ìš°ì—ë§Œ ë‹¤ìš´ìŠ¤ì¼€ì¼ë©ë‹ˆë‹¤
    - **ìë™ ì¡°ì •**: 8ì˜ ë°°ìˆ˜ë¡œ ìë™ ì¡°ì •ë˜ì–´ SDXLê³¼ ì™„ë²½ í˜¸í™˜ë©ë‹ˆë‹¤
    - **ìµœì†Œ í¬ê¸°**: 512px ë¯¸ë§Œì¸ ê²½ìš° 512pxë¡œ ì—…ìŠ¤ì¼€ì¼ë©ë‹ˆë‹¤
    - **Strength**: 0.3-0.5 (ì•½ê°„ ìˆ˜ì •), 0.6-0.8 (ë³´í†µ ìˆ˜ì •), 0.9-1.0 (ê°•í•œ ìˆ˜ì •)
    - **Guidance Scale**: 7-12 ì¶”ì²œ (ë„ˆë¬´ ë†’ìœ¼ë©´ ê³¼í¬í™”ë  ìˆ˜ ìˆìŒ)
    - **ì¢‹ì€ í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ**: "professional photography, high resolution, detailed, sharp focus"
    - **ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸**: "blurry, low quality, distorted, ugly, deformed" ë“±ìœ¼ë¡œ ì›í•˜ì§€ ì•ŠëŠ” ìš”ì†Œ ì œê±°
    - **ì§€ì› í•´ìƒë„**: ëª¨ë“  ë¹„ìœ¨ê³¼ í¬ê¸° ì§€ì› (ì›ë³¸ì— ìµœëŒ€í•œ ê°€ê¹ê²Œ ìœ ì§€)
    """)
    
    # ì´ë²¤íŠ¸ ì—°ê²°
    generate_btn.click(
        fn=generate_image,
        inputs=[input_image, prompt, negative_prompt, strength, guidance_scale, num_inference_steps],
        outputs=[output_image, status_text],
        show_progress=True
    )

if __name__ == "__main__":
    demo.launch(share=False, inbrowser=True)
