import torch
import gradio as gr
import time
from diffusers import FluxKontextPipeline
from diffusers.utils import load_image
from PIL import Image
import os

# Dependency!!! :
# You need to install the diffusers with the following command:
# pip install git+https://github.com/huggingface/diffusers.git

# Load model with memory optimizations
print("ëª¨ë¸ì„ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤...")
pipe = FluxKontextPipeline.from_pretrained(
    "black-forest-labs/FLUX.1-Kontext-dev", torch_dtype=torch.bfloat16
)

# Enable multiple memory optimizations
pipe.enable_model_cpu_offload()  # Offload model to CPU when not in use
pipe.enable_sequential_cpu_offload()  # More aggressive CPU offloading
pipe.enable_attention_slicing(1)  # Slice attention computation
pipe.enable_vae_slicing()  # Slice VAE computation
print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")


# ê¸°ë³¸ ì´ë¯¸ì§€ ë¡œë“œ í•¨ìˆ˜
def load_default_image():
    """ê¸°ë³¸ ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ë¡œë“œ"""
    default_path = "default.jpg"
    if os.path.exists(default_path):
        try:
            return load_image(default_path)
        except Exception as e:
            print(f"ê¸°ë³¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    return None


def generate_image(
    prompt,
    input_image,
    width,
    height,
    guidance_scale,
    num_inference_steps,
    max_sequence_length,
    strength,
    seed,
):
    """ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ (í…ìŠ¤íŠ¸-íˆ¬-ì´ë¯¸ì§€ ë˜ëŠ” ì´ë¯¸ì§€-íˆ¬-ì´ë¯¸ì§€)"""
    start_time = time.time()

    # ì…ë ¥ ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° í•´ë‹¹ ì´ë¯¸ì§€ì˜ ë¹„ìœ¨ ì‚¬ìš©
    if input_image is not None:
        input_width, input_height = input_image.size
        aspect_ratio = input_width / input_height

        # ì…ë ¥ ì´ë¯¸ì§€ ë¹„ìœ¨ì— ë§ì¶° í¬ê¸° ì¡°ì •
        if aspect_ratio >= 1.0:  # ê°€ë¡œê°€ ë” í¬ê±°ë‚˜ ê°™ì€ ê²½ìš°
            adjusted_width = max(768, int(width))
            adjusted_height = int(adjusted_width / aspect_ratio)
        else:  # ì„¸ë¡œê°€ ë” í° ê²½ìš°
            adjusted_height = max(768, int(height))
            adjusted_width = int(adjusted_height * aspect_ratio)

        # 16ì˜ ë°°ìˆ˜ë¡œ ì¡°ì •
        adjusted_width = (adjusted_width // 16) * 16
        adjusted_height = (adjusted_height // 16) * 16

        # ìµœì†Œ í¬ê¸° ë³´ì¥
        adjusted_width = max(adjusted_width, 512)
        adjusted_height = max(adjusted_height, 512)

        generation_type = "ì´ë¯¸ì§€ íˆ¬ ì´ë¯¸ì§€"

    else:
        # ê¸°ë³¸ ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
        default_image = load_default_image()
        if default_image is not None:
            # ê¸°ë³¸ ì´ë¯¸ì§€ì˜ ë¹„ìœ¨ ì‚¬ìš©
            default_width, default_height = default_image.size
            aspect_ratio = default_width / default_height

            # ê¸°ë³¸ ì´ë¯¸ì§€ ë¹„ìœ¨ì— ë§ì¶° í¬ê¸° ì¡°ì •
            if aspect_ratio >= 1.0:  # ê°€ë¡œê°€ ë” í¬ê±°ë‚˜ ê°™ì€ ê²½ìš°
                adjusted_width = max(768, int(width))
                adjusted_height = int(adjusted_width / aspect_ratio)
            else:  # ì„¸ë¡œê°€ ë” í° ê²½ìš°
                adjusted_height = max(768, int(height))
                adjusted_width = int(adjusted_height * aspect_ratio)

            # 16ì˜ ë°°ìˆ˜ë¡œ ì¡°ì •
            adjusted_width = (adjusted_width // 16) * 16
            adjusted_height = (adjusted_height // 16) * 16

            # ìµœì†Œ í¬ê¸° ë³´ì¥
            adjusted_width = max(adjusted_width, 512)
            adjusted_height = max(adjusted_height, 512)

            generation_type = "ê¸°ë³¸ì´ë¯¸ì§€-íˆ¬-ì´ë¯¸ì§€"
        else:
            # ì‚¬ìš©ì ì§€ì • í¬ê¸° ì‚¬ìš©
            width = int(width)
            height = int(height)
            aspect_ratio = width / height

            # 16ì˜ ë°°ìˆ˜ë¡œ ì¡°ì •
            adjusted_width = (width // 16) * 16
            adjusted_height = (height // 16) * 16

            # ìµœì†Œ í¬ê¸° ë³´ì¥í•˜ë©´ì„œ ë¹„ìœ¨ ìœ ì§€
            if adjusted_width < 512 or adjusted_height < 512:
                if aspect_ratio >= 1.0:  # ê°€ë¡œê°€ ë” í¬ê±°ë‚˜ ê°™ì€ ê²½ìš°
                    adjusted_height = 512
                    adjusted_width = int(512 * aspect_ratio)
                    adjusted_width = (adjusted_width // 16) * 16
                else:  # ì„¸ë¡œê°€ ë” í° ê²½ìš°
                    adjusted_width = 512
                    adjusted_height = int(512 / aspect_ratio)
                    adjusted_height = (adjusted_height // 16) * 16

            # ìµœì¢… ìµœì†Œ í¬ê¸° í™•ì¸
            adjusted_width = max(adjusted_width, 512)
            adjusted_height = max(adjusted_height, 512)

            generation_type = "í…ìŠ¤íŠ¸ íˆ¬ ì´ë¯¸ì§€"

    # ì‹œë“œ ì„¤ì •
    if seed == -1:
        seed = torch.randint(0, 2**32 - 1, (1,)).item()

    generator = torch.Generator("cpu").manual_seed(seed)

    try:
        # ì…ë ¥ ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° img2img, ì—†ëŠ” ê²½ìš° txt2img
        if input_image is not None:
            # ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
            input_image = input_image.resize(
                (adjusted_width, adjusted_height), Image.LANCZOS
            )

            # img2img ìƒì„±
            image = pipe(
                prompt=prompt,
                image=input_image,
                height=adjusted_height,
                width=adjusted_width,
                guidance_scale=guidance_scale,
                num_inference_steps=int(num_inference_steps),
                max_sequence_length=int(max_sequence_length),
                generator=generator,
            ).images[0]

        else:
            # ê¸°ë³¸ ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
            default_image = load_default_image()
            if default_image is not None:
                # ê¸°ë³¸ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•œ img2img
                default_image = default_image.resize(
                    (adjusted_width, adjusted_height), Image.LANCZOS
                )

                image = pipe(
                    prompt=prompt,
                    image=default_image,
                    height=adjusted_height,
                    width=adjusted_width,
                    guidance_scale=guidance_scale,
                    num_inference_steps=int(num_inference_steps),
                    max_sequence_length=int(max_sequence_length),
                    generator=generator,
                ).images[0]

            else:
                # txt2img ìƒì„±
                image = pipe(
                    prompt=prompt,
                    height=adjusted_height,
                    width=adjusted_width,
                    guidance_scale=guidance_scale,
                    num_inference_steps=int(num_inference_steps),
                    max_sequence_length=int(max_sequence_length),
                    generator=generator,
                ).images[0]

        end_time = time.time()
        generation_time = end_time - start_time

        # ì´ë¯¸ì§€ ì €ì¥
        timestamp = int(time.time())
        filename = f"flux_generated_{timestamp}.png"
        image.save(filename)

        # ìƒì„±ëœ ì´ë¯¸ì§€ í¬ê¸° ì •ë³´
        generated_width, generated_height = image.size

        # í¬ê¸° ì¡°ì • ì •ë³´ í¬í•¨
        size_info = f"\nìƒì„±ëœ ì´ë¯¸ì§€ í¬ê¸°: {generated_width}x{generated_height}"
        if input_image is not None:
            original_width, original_height = input_image.size
            size_info += f"\nì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°: {original_width}x{original_height}"
            size_info += f"\në¹„ìœ¨ ë§ì¶¤: {original_width/original_height:.2f} â†’ {generated_width/generated_height:.2f}"
        elif default_image is not None:
            default_width, default_height = default_image.size
            size_info += f"\nê¸°ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {default_width}x{default_height}"
            size_info += f"\në¹„ìœ¨ ë§ì¶¤: {default_width/default_height:.2f} â†’ {generated_width/generated_height:.2f}"
        else:
            size_info += f"\nìš”ì²­ í¬ê¸°: {width}x{height}"

        info_text = f"ìƒì„± ì™„ë£Œ! ({generation_type})\nì‹œê°„: {generation_time:.2f}ì´ˆ\nì‹œë“œ: {seed}\nì €ì¥ëœ íŒŒì¼: {filename}{size_info}"

        return image, info_text

    except Exception as e:
        error_text = f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        return None, error_text


def update_ui_visibility(input_image):
    """ì…ë ¥ ì´ë¯¸ì§€ì— ë”°ë¼ UI ìš”ì†Œ í‘œì‹œ/ìˆ¨ê¹€ ë° ê¸°ë³¸ ì´ë¯¸ì§€ í‘œì‹œ"""
    if input_image is not None:
        return gr.update(visible=False), gr.update(
            value="ì´ë¯¸ì§€ë¥¼ í”„ë¡¬í”„íŠ¸ì— ë§ê²Œ ìˆ˜ì •í•©ë‹ˆë‹¤..."
        )
    else:
        # ê¸°ë³¸ ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  í‘œì‹œ
        default_image = load_default_image()
        if default_image is not None:
            return gr.update(visible=False), gr.update(
                value="ê¸°ë³¸ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ì— ë§ê²Œ ìˆ˜ì •í•©ë‹ˆë‹¤..."
            )
        else:
            return gr.update(visible=False), gr.update(
                value="ìƒì„±í•˜ê³  ì‹¶ì€ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”..."
            )


# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±
with gr.Blocks(title="FLUX.1-dev ì´ë¯¸ì§€ ìƒì„±ê¸°") as demo:
    gr.Markdown("# ğŸ¨ FLUX.1-dev ì´ë¯¸ì§€ ìƒì„±ê¸°")
    gr.Markdown(
        "í…ìŠ¤íŠ¸ë¡œ ìƒˆ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê±°ë‚˜, ê¸°ì¡´ ì´ë¯¸ì§€ë¥¼ í”„ë¡¬í”„íŠ¸ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”!"
    )

    # ê¸°ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
    default_img = load_default_image()

    with gr.Row():
        with gr.Column(scale=1):
            default_prompt = "photorealistic, 8k resolution, ultra detailed, vibrant colors, cinematic lighting, realistic shadows, high quality, masterpiece, best quality, looking at viewer, perfect anatomy"
            # ì…ë ¥ ì´ë¯¸ì§€ (ì„ íƒì‚¬í•­)
            input_image = gr.Image(
                label="ì…ë ¥ ì´ë¯¸ì§€ (ì„ íƒì‚¬í•­)",
                type="pil",
                sources=["upload", "clipboard"],
                value=default_img,
            )

            # ê¸°ë³¸ ì´ë¯¸ì§€ ìƒíƒœ í‘œì‹œ
            if default_img is not None:
                gr.Markdown(
                    "ğŸ’¡ **ê¸°ë³¸ ì´ë¯¸ì§€ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.** ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
                )

            # ì…ë ¥ ì»¨íŠ¸ë¡¤ë“¤
            prompt_input = gr.Textbox(
                label="í”„ë¡¬í”„íŠ¸",
                placeholder="ìƒì„±í•˜ê³  ì‹¶ì€ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”...",
                value="skinny, blue eyes, full body, beautiful face, good body shape, good hair, good fingers, good legs",
                lines=4,
            )
            
            prompt = prompt_input + default_prompt

            with gr.Row():
                width_slider = gr.Slider(
                    minimum=256, maximum=1024, value=768, step=64, label="ë„ˆë¹„"
                )
                height_slider = gr.Slider(
                    minimum=256, maximum=1024, value=768, step=64, label="ë†’ì´"
                )

            guidance_slider = gr.Slider(
                minimum=1.0, maximum=10.0, value=3.5, step=0.1, label="ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼"
            )

            steps_slider = gr.Slider(
                minimum=10, maximum=50, value=28, step=1, label="ì¶”ë¡  ìŠ¤í… ìˆ˜"
            )

            sequence_slider = gr.Slider(
                minimum=128, maximum=512, value=256, step=32, label="ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´"
            )

            # ì´ë¯¸ì§€-íˆ¬-ì´ë¯¸ì§€ ì „ìš© ì„¤ì •
            strength_slider = gr.Slider(
                minimum=0.1,
                maximum=1.0,
                value=0.5,  # ê¸°ë³¸ê°’ì„ 0.5ë¡œ ë‚®ì¶¤ (ì›ë³¸ ë” ë³´ì¡´)
                step=0.1,
                label="ë³€í˜• ê°•ë„ (ë‚®ì„ìˆ˜ë¡ ì›ë³¸ ìœ ì§€)",
                visible=True if default_img is not None else False,
            )

            seed_input = gr.Number(label="ì‹œë“œ (-1ì€ ëœë¤)", value=-1, precision=0)
            generate_btn = gr.Button("ğŸ¨ ì´ë¯¸ì§€ ìƒì„±", variant="primary", size="lg")

        with gr.Column(scale=1):
            # ì¶œë ¥ ì˜ì—­
            output_image = gr.Image(label="ìƒì„±ëœ ì´ë¯¸ì§€", type="pil", height=500)
            info_output = gr.Textbox(label="ìƒì„± ì •ë³´", lines=4, interactive=False)

    # ì´ë²¤íŠ¸ ì—°ê²°
    input_image.change(
        fn=update_ui_visibility,
        inputs=[input_image],
        outputs=[strength_slider, prompt_input],
    )

    generate_btn.click(
        fn=generate_image,
        inputs=[
            prompt_input,
            input_image,
            width_slider,
            height_slider,
            guidance_slider,
            steps_slider,
            sequence_slider,
            strength_slider,
            seed_input,
        ],
        outputs=[output_image, info_output],
    )

    # ì˜ˆì œ í”„ë¡¬í”„íŠ¸
    gr.Examples(
        examples=[
            ["a cute cat holding a sign that says hello world"],
            ["a futuristic city skyline at sunset, cyberpunk style"],
            ["a beautiful landscape with mountains and a lake, oil painting style"],
            ["a portrait of a woman with blue eyes, renaissance painting style"],
            ["a magical forest with glowing mushrooms, fantasy art"],
            ["convert this image to anime style, vibrant colors"],
            ["make this image look like a watercolor painting"],
            ["transform this to a cyberpunk style with neon lights"],
        ],
        inputs=prompt_input,
    )

if __name__ == "__main__":
    demo.launch(share=False, inbrowser=True)
