import torch
import gradio as gr
from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline
from PIL import Image


# ëª¨ë¸ ë¡œë”© (í•œ ë²ˆë§Œ ì‹¤í–‰)
try:
    base = StableDiffusionXLPipeline.from_pretrained(
        "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
    )
    base.enable_model_cpu_offload()
    base = base.to("cpu")
    print("> stable-diffusion-xl-base-1.0 ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
except Exception as e:
    print(f"ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    base = None

try: 
    refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(
        "stabilityai/stable-diffusion-xl-refiner-1.0",
        torch_dtype=torch.float16,
        variant="fp16",
        use_safetensors=True,
        )
    refiner.enable_model_cpu_offload()
    refiner = refiner.to("cpu")
    print("> stable-diffusion-xl-refiner-1.0 ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
except Exception as e:
    print(f"ë¦¬íŒŒì´ë„ˆ ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    refiner = None


def resize_image_to_sdxl(image, max_size=1024):
    """ì´ë¯¸ì§€ë¥¼ SDXLì— ì í•©í•œ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆí•˜ë©´ì„œ ì›ë³¸ í¬ê¸° ìµœëŒ€í•œ ìœ ì§€ (í˜„ì¬ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)"""
    width, height = image.size
    
    # ì›ë³¸ í¬ê¸°ê°€ ë„ˆë¬´ í° ê²½ìš°ì—ë§Œ ë‹¤ìš´ìŠ¤ì¼€ì¼
    if max(width, height) > max_size:
        aspect_ratio = width / height
        if width > height:
            new_width = max_size
            new_height = int(max_size / aspect_ratio)
        else:
            new_height = max_size
            new_width = int(max_size * aspect_ratio)
    else:
        # ì›ë³¸ í¬ê¸° ìœ ì§€
        new_width = width
        new_height = height
    
    # 8ì˜ ë°°ìˆ˜ë¡œ ì¡°ì • (Stable Diffusion ìš”êµ¬ì‚¬í•­)
    new_width = (new_width // 8) * 8
    new_height = (new_height // 8) * 8
    
    # ìµœì†Œ í¬ê¸° ë³´ì¥ (512px ë¯¸ë§Œì¸ ê²½ìš°ë§Œ)
    if new_width < 512:
        new_width = 512
    if new_height < 512:
        new_height = 512
    
    # ì›ë³¸ê³¼ í¬ê¸°ê°€ ê°™ìœ¼ë©´ ë¦¬ì‚¬ì´ì¦ˆ í•˜ì§€ ì•ŠìŒ
    if new_width == width and new_height == height:
        return image
    
    return image.resize((new_width, new_height), Image.Resampling.LANCZOS)


def generate_image(prompt, negative_prompt, width, height, strength, guidance_scale, num_inference_steps, progress=gr.Progress()):
    if not prompt.strip():
        return None, None, "Promptë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    if base is None or refiner is None:
        return None, None, "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    try:
        progress(0, desc="ì´ë¯¸ì§€ ìƒì„± ì‹œì‘...")
        
        # í¬ê¸°ë¥¼ 8ì˜ ë°°ìˆ˜ë¡œ ì¡°ì •
        width = (width // 8) * 8
        height = (height // 8) * 8
        
        progress(0.1, desc="ë² ì´ìŠ¤ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
        
        # 1ë‹¨ê³„: ë² ì´ìŠ¤ ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„±
        base_image = base(
            prompt=prompt,
            negative_prompt=negative_prompt,
            width=width,
            height=height,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            denoising_end=1.0,  # ë² ì´ìŠ¤ëŠ” ?(ì†Œìˆ˜ì )ê¹Œì§€ë§Œ ìƒì„±
            output_type="latent"  # latent í˜•íƒœë¡œ ì¶œë ¥í•˜ì—¬ refinerì— ì „ë‹¬
        ).images[0]
        
        progress(0.6, desc="ë¦¬íŒŒì´ë„ˆë¡œ ì´ë¯¸ì§€ ì •ì œ ì¤‘...")
        
        # 2ë‹¨ê³„: ë¦¬íŒŒì´ë„ˆë¡œ ì´ë¯¸ì§€ ì •ì œ
        refined_image = refiner(
            prompt=prompt,
            negative_prompt=negative_prompt,
            image=base_image,
            num_inference_steps=num_inference_steps,
            denoising_start=0.8,  # ë² ì´ìŠ¤ì—ì„œ 80% ì™„ë£Œëœ ì§€ì ë¶€í„° ì‹œì‘
            strength=strength,
            guidance_scale=guidance_scale,
        ).images[0]
        
        progress(0.9, desc="ì´ë¯¸ì§€ ì €ì¥ ì¤‘...")
        
        # ë² ì´ìŠ¤ ì´ë¯¸ì§€ë„ PILë¡œ ë³€í™˜í•´ì„œ ë¹„êµìš©ìœ¼ë¡œ ì €ì¥
        base_pil = base(
            prompt=prompt,
            negative_prompt=negative_prompt,
            width=width,
            height=height,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            denoising_end=0.8
        ).images[0]
        
        progress(1.0, desc="ì™„ë£Œ!")
        status_message = "ì´ë¯¸ì§€ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!"
        return base_pil, refined_image, status_message
        
    except Exception as e:
        return None, None, f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±
with gr.Blocks(title="Stable Diffusion XL Base + Refiner", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ¨ Stable Diffusion XL Base + Refiner")
    gr.Markdown("í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì—¬ ë² ì´ìŠ¤ ëª¨ë¸ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³ , ë¦¬íŒŒì´ë„ˆë¡œ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ë³´ì„¸ìš”.")
    
    with gr.Row():
        with gr.Column(scale=1):
            # ì…ë ¥ ì»¨íŠ¸ë¡¤
            prompt = gr.Textbox(
                label="Prompt (í”„ë¡¬í”„íŠ¸)",
                placeholder="ì˜ˆ: a beautiful woman in red bikini walking on sunny beach",
                lines=3,
                value="a beautiful woman in red bikini walking on sunny beach, ultra high quality, ultra detail, photorealistic, vibrant colors, full body, good fingers"
            )
            
            negative_prompt = gr.Textbox(
                label="Negative Prompt (ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸)",
                placeholder="ì˜ˆ: blurry, low quality, distorted, ugly",
                lines=2,
                value="blurry, low quality, distorted, ugly, deformed, bad anatomy"
            )
            
            with gr.Row():
                width = gr.Slider(
                    label="ë„ˆë¹„",
                    minimum=512,
                    maximum=1536,
                    value=1024,
                    step=64,
                    info="8ì˜ ë°°ìˆ˜ë¡œ ìë™ ì¡°ì •ë©ë‹ˆë‹¤"
                )
                
                height = gr.Slider(
                    label="ë†’ì´",
                    minimum=512,
                    maximum=1536,
                    value=1024,
                    step=64,
                    info="8ì˜ ë°°ìˆ˜ë¡œ ìë™ ì¡°ì •ë©ë‹ˆë‹¤"
                )
            
            with gr.Accordion("ê³ ê¸‰ ì„¤ì •", open=False):
                strength = gr.Slider(
                    label="Refiner Strength (ë¦¬íŒŒì´ë„ˆ ê°•ë„)",
                    minimum=0.1,
                    maximum=1.0,
                    value=0.3,
                    step=0.05,
                    info="ë¦¬íŒŒì´ë„ˆì˜ ë³€í˜• ê°•ë„"
                )
                
                guidance_scale = gr.Slider(
                    label="Guidance Scale",
                    minimum=1.0,
                    maximum=20.0,
                    value=7.5,
                    step=0.5,
                    info="í”„ë¡¬í”„íŠ¸ ì¤€ìˆ˜ ì •ë„"
                )
                
                num_inference_steps = gr.Slider(
                    label="Inference Steps",
                    minimum=20,
                    maximum=50,
                    value=40,
                    step=5,
                    info="ìƒì„± ë‹¨ê³„ ìˆ˜ (ë†’ì„ìˆ˜ë¡ í’ˆì§ˆ í–¥ìƒ, ì‹œê°„ ì¦ê°€)"
                )
            
            generate_btn = gr.Button("ğŸ¨ ì´ë¯¸ì§€ ìƒì„±", variant="primary", size="lg")
            
        with gr.Column(scale=2):
            # ì¶œë ¥ ê²°ê³¼
            with gr.Row():
                base_output = gr.Image(
                    label="ë² ì´ìŠ¤ ì´ë¯¸ì§€ (Base Model)",
                    height=350
                )
                
                refined_output = gr.Image(
                    label="ë¦¬íŒŒì¸ëœ ì´ë¯¸ì§€ (Refined)",
                    height=350
                )
            
            status_text = gr.Textbox(
                label="ìƒíƒœ",
                value="í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ê³  'ì´ë¯¸ì§€ ìƒì„±' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.",
                interactive=False,
                lines=4
            )
    
    # ì˜ˆì‹œ ì´ë¯¸ì§€ì™€ í”„ë¡¬í”„íŠ¸
    gr.Markdown("## ğŸ“ ì‚¬ìš© íŒ")
    gr.Markdown("""
    - **2ë‹¨ê³„ ìƒì„±**: ë² ì´ìŠ¤ ëª¨ë¸ë¡œ ì´ˆê¸° ì´ë¯¸ì§€ ìƒì„± â†’ ë¦¬íŒŒì´ë„ˆë¡œ í’ˆì§ˆ í–¥ìƒ
    - **denoising ë¶„í• **: ë² ì´ìŠ¤ 80% â†’ ë¦¬íŒŒì´ë„ˆ 20%ë¡œ íš¨ìœ¨ì  ì²˜ë¦¬
    - **í•´ìƒë„**: 512px~1536px ì§€ì›, 8ì˜ ë°°ìˆ˜ë¡œ ìë™ ì¡°ì •
    - **Refiner Strength**: 0.1-0.3 (ì•½ê°„ ê°œì„ ), 0.4-0.7 (ë³´í†µ ê°œì„ ), 0.8-1.0 (ê°•í•œ ê°œì„ )
    - **Guidance Scale**: 7-12 ì¶”ì²œ (ë„ˆë¬´ ë†’ìœ¼ë©´ ê³¼í¬í™”ë  ìˆ˜ ìˆìŒ)
    - **Inference Steps**: 30-50 ì¶”ì²œ (ë†’ì„ìˆ˜ë¡ ê³ í’ˆì§ˆ, ì‹œê°„ ì¦ê°€)
    - **ì¢‹ì€ í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ**: "photorealistic portrait, professional photography, high quality, detailed"
    - **ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸**: "blurry, low quality, distorted, ugly, deformed" ë“±ìœ¼ë¡œ ì›í•˜ì§€ ì•ŠëŠ” ìš”ì†Œ ì œê±°
    """)
    
    # ì´ë²¤íŠ¸ ì—°ê²°
    generate_btn.click(
        fn=generate_image,
        inputs=[prompt, negative_prompt, width, height, strength, guidance_scale, num_inference_steps],
        outputs=[base_output, refined_output, status_text],
        show_progress=True
    )

if __name__ == "__main__":
    demo.launch(share=False, inbrowser=True)
