import torch
import gradio as gr
from diffusers import StableDiffusionXLImg2ImgPipeline
import datetime

refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-refiner-1.0",
    torch_dtype=torch.float16,
    variant="fp16",
    use_safetensors=True,
    )
refiner.enable_model_cpu_offload()
refiner.enable_sequential_cpu_offload()
refiner.enable_attention_slicing()

print("> stable-diffusion-xl-refiner-1.0 ëª¨ë¸ ë¡œë“œ ì„±ê³µ")


def generate_image(input_image, prompt, negative_prompt, strength, guidance_scale, num_inference_steps):
    try:
        # 2ë‹¨ê³„: ë¦¬íŒŒì´ë„ˆë¡œ ì´ë¯¸ì§€ ì •ì œ
        refined_image = refiner(
            prompt=prompt,
            negative_prompt=negative_prompt,
            image=input_image,
            width=input_image.width,
            height=input_image.height,
            num_inference_steps=num_inference_steps,
            denoising_start=0.8,  # ë² ì´ìŠ¤ì—ì„œ 80% ì™„ë£Œëœ ì§€ì ë¶€í„° ì‹œì‘
            strength=strength,
            guidance_scale=guidance_scale,
        ).images[0]
        # ì´ë¯¸ì§€ ì €ì¥ (ì„ íƒ ì‚¬í•­)
        refined_image.save(f"sdxl-refiner-{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}.png")
        return refined_image
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±
with gr.Blocks(title="Stable Diffusion XL Refiner", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ¨ Stable Diffusion XL Refiner")
    gr.Markdown("í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì—¬ ë¦¬íŒŒì´ë„ˆë¡œ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ë³´ì„¸ìš”.")

    with gr.Row():
        with gr.Column():
            # ì…ë ¥ ì»¨íŠ¸ë¡¤
            input_image = gr.Image(
                label="ì…ë ¥ ì´ë¯¸ì§€ (Input Image)",
                type="pil",
                height=500,
                value="default.jpg",  # ê¸°ë³¸ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            )

            prompt = gr.Textbox(
                label="Prompt (í”„ë¡¬í”„íŠ¸)",
                lines=3,
                value="8k uhd, high detail, high quality, ultra high resolution",
                info="ì´ë¯¸ì§€ì— ì›í•˜ëŠ” íŠ¹ì§•, ìŠ¤íƒ€ì¼, ë¶„ìœ„ê¸° ë“±ì„ ì˜ì–´ë¡œ ì…ë ¥í•˜ì„¸ìš”."
            )

            negative_prompt = gr.Textbox(
                label="Negative Prompt (ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸)",
                placeholder="ì˜ˆ: blurry, low quality, distorted, ugly",
                lines=3,
                value="blurry, low quality, distorted, ugly, deformed, bad anatomy",
                info="ì´ë¯¸ì§€ì—ì„œ í”¼í•˜ê³  ì‹¶ì€ ìš”ì†Œë¥¼ ì˜ì–´ë¡œ ì…ë ¥í•˜ì„¸ìš”."
            )


            strength = gr.Slider(
                label="Refiner Strength (ë¦¬íŒŒì´ë„ˆ ê°•ë„)",
                minimum=0.1,
                maximum=1.0,
                value=0.80,
                step=0.05,
                info="ë¦¬íŒŒì´ë„ˆê°€ ì´ë¯¸ì§€ë¥¼ ì–¼ë§ˆë‚˜ ë§ì´ ìˆ˜ì •í• ì§€ ê²°ì •í•©ë‹ˆë‹¤. ë‚®ì„ìˆ˜ë¡ ì›ë³¸ ìœ ì§€, ë†’ì„ìˆ˜ë¡ ë³€í™” í¼."
            )

            guidance_scale = gr.Slider(
                label="Guidance Scale (í”„ë¡¬í”„íŠ¸ ë°˜ì˜ ì •ë„)",
                minimum=1.0,
                maximum=20.0,
                value=7.5,
                step=0.1,
                info="í”„ë¡¬í”„íŠ¸ë¥¼ ì–¼ë§ˆë‚˜ ê°•í•˜ê²Œ ë°˜ì˜í• ì§€ ê²°ì •í•©ë‹ˆë‹¤. ë„ˆë¬´ ë†’ìœ¼ë©´ ë¶€ìì—°ìŠ¤ëŸ¬ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )

            num_inference_steps = gr.Slider(
                label="Inference Steps (ìƒì„± ë‹¨ê³„ ìˆ˜)",
                minimum=20,
                maximum=50,
                value=50,
                step=1,
                info="ì´ë¯¸ì§€ ìƒì„± í’ˆì§ˆê³¼ ì†ë„ì— ì˜í–¥ì„ ì¤ë‹ˆë‹¤. ë†’ì„ìˆ˜ë¡ í’ˆì§ˆì´ ì¢‹ì•„ì§€ì§€ë§Œ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤."
            )

            generate_btn = gr.Button("ğŸ¨ ì´ë¯¸ì§€ ìƒì„±", variant="primary", size="lg")

        with gr.Column():
            refined_output = gr.Image(
                label="ë¦¬íŒŒì¸ëœ ì´ë¯¸ì§€ (Refined)",
                height=500,
            )

    generate_btn.click(
        fn=generate_image,
        inputs=[input_image, prompt, negative_prompt, strength, guidance_scale, num_inference_steps],
        outputs=[refined_output],
    )

if __name__ == "__main__":
    demo.launch(share=False, inbrowser=True)