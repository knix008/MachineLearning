import torch
import gradio as gr
from diffusers.utils import load_image, check_min_version
from diffusers.pipelines import StableDiffusion3ControlNetInpaintingPipeline
from diffusers.models.controlnets.controlnet_sd3 import SD3ControlNetModel
from PIL import Image, ImageDraw
import datetime
import numpy as np

# ëª¨ë¸ ë¡œë”©
print("ëª¨ë¸ ë¡œë”© ì¤‘...")
controlnet = SD3ControlNetModel.from_pretrained(
    "alimama-creative/SD3-Controlnet-Inpainting", 
    use_safetensors=True, 
    extra_conditioning_channels=1,
    torch_dtype=torch.float16
)

# Inpainting íŒŒì´í”„ë¼ì¸ ìƒì„± 
pipe = StableDiffusion3ControlNetInpaintingPipeline.from_pretrained(
    "stabilityai/stable-diffusion-3-medium-diffusers",
    controlnet=controlnet,
    torch_dtype=torch.float16,
    variant="fp16",
    use_safetensors=True
)

# ë©”ëª¨ë¦¬ ìµœì í™”
pipe.enable_model_cpu_offload()
pipe.enable_attention_slicing(1)
pipe.to("cpu")
print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

def resize_image_for_sd3(image, target_size=1024):
    """ì´ë¯¸ì§€ë¥¼ SD3ì— ì í•©í•œ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (16ì˜ ë°°ìˆ˜, ë¹„ìœ¨ ìœ ì§€)"""
    width, height = image.size
    aspect_ratio = width / height
    
    # ê¸´ ìª½ì„ ê¸°ì¤€ìœ¼ë¡œ target_sizeì— ë§ì¶¤
    if width > height:
        new_width = target_size
        new_height = int(target_size / aspect_ratio)
    else:
        new_height = target_size
        new_width = int(target_size * aspect_ratio)
    
    # 16ì˜ ë°°ìˆ˜ë¡œ ì¡°ì • (ë¹„ìœ¨ì„ ìµœëŒ€í•œ ìœ ì§€)
    new_width = max(512, (new_width // 16) * 16)
    new_height = max(512, (new_height // 16) * 16)
    
    # ì¡°ì •ëœ í¬ê¸°ë¡œ ë¹„ìœ¨ ì¬ê³„ì‚°í•˜ì—¬ ë” ì •í™•í•˜ê²Œ ë§ì¶¤
    adjusted_ratio = new_width / new_height
    
    # ì›ë³¸ ë¹„ìœ¨ê³¼ ì°¨ì´ê°€ í´ ê²½ìš° ë” ì •í™•í•˜ê²Œ ì¡°ì •
    if abs(aspect_ratio - adjusted_ratio) > 0.1:
        if aspect_ratio > adjusted_ratio:
            # ë„ˆë¹„ë¥¼ ëŠ˜ë ¤ì•¼ í•¨
            new_width = min(new_width + 16, target_size + 256)
        else:
            # ë†’ì´ë¥¼ ëŠ˜ë ¤ì•¼ í•¨
            new_height = min(new_height + 16, target_size + 256)
    
    return image.resize((new_width, new_height), Image.Resampling.LANCZOS)

def create_center_mask(image, mask_ratio=0.3):
    """ì´ë¯¸ì§€ ì¤‘ì•™ì— ì›í˜• ë§ˆìŠ¤í¬ ìƒì„±"""
    width, height = image.size
    mask = Image.new("L", (width, height), 0)
    draw = ImageDraw.Draw(mask)
    
    # ì¤‘ì•™ ì¢Œí‘œ
    center_x, center_y = width // 2, height // 2
    
    # ë§ˆìŠ¤í¬ í¬ê¸° (ì´ë¯¸ì§€ í¬ê¸°ì˜ ì¼ì • ë¹„ìœ¨)
    radius = min(width, height) * mask_ratio // 2
    
    # ì›í˜• ë§ˆìŠ¤í¬ ê·¸ë¦¬ê¸° (í°ìƒ‰ = ë³€ê²½í•  ì˜ì—­)
    draw.ellipse([
        center_x - radius, center_y - radius,
        center_x + radius, center_y + radius
    ], fill=255)
    
    return mask

def create_edge_mask(image, edge_threshold=100):
    """ì´ë¯¸ì§€ì˜ ì—£ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§ˆìŠ¤í¬ ìƒì„±"""
    # PIL ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
    img_array = np.array(image.convert("RGB"))
    
    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
    gray = np.dot(img_array[...,:3], [0.2989, 0.5870, 0.1140])
    
    # ê°„ë‹¨í•œ ì—£ì§€ ê²€ì¶œ (Sobel-like)
    grad_x = np.abs(np.diff(gray, axis=1))
    grad_y = np.abs(np.diff(gray, axis=0))
    
    # íŒ¨ë”©ì„ ì¶”ê°€í•˜ì—¬ ì›ë³¸ í¬ê¸° ìœ ì§€
    grad_x = np.pad(grad_x, ((0, 0), (0, 1)), mode='edge')
    grad_y = np.pad(grad_y, ((0, 1), (0, 0)), mode='edge')
    
    # ê·¸ë˜ë””ì–¸íŠ¸ í¬ê¸° ê³„ì‚°
    gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
    
    # ì„ê³„ê°’ì„ ì´ˆê³¼í•˜ëŠ” ì˜ì—­ì„ ë§ˆìŠ¤í¬ë¡œ ì„¤ì •
    mask_array = (gradient_magnitude > edge_threshold).astype(np.uint8) * 255
    
    return Image.fromarray(mask_array, mode="L")

def enhance_image_quality(
    input_image,
    prompt,
    negative_prompt,
    mask_type,
    mask_size,
    num_inference_steps,
    guidance_scale,
    controlnet_conditioning_scale,
    seed,
    target_size,
    progress=gr.Progress()
):
    """ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜"""
    try:
        progress(0.1, desc="ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘...")
        
        if input_image is None:
            return None, None, "ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
        
        # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
        input_image = resize_image_for_sd3(input_image, target_size)
        
        # ë§ˆìŠ¤í¬ ìë™ ìƒì„±
        progress(0.2, desc="ë§ˆìŠ¤í¬ ìƒì„± ì¤‘...")
        if mask_type == "ì¤‘ì•™ ì›í˜•":
            mask_image = create_center_mask(input_image, mask_size)
        elif mask_type == "ì—£ì§€ ê¸°ë°˜":
            mask_image = create_edge_mask(input_image, int(mask_size * 255))
        else:  # ì „ì²´ ì˜ì—­
            mask_image = Image.new("L", input_image.size, 255)
        
        width, height = input_image.size
        progress(0.3, desc="ìƒì„± ë§¤ê°œë³€ìˆ˜ ì„¤ì • ì¤‘...")
        
        # ì‹œë“œ ì„¤ì •
        if seed == -1:
            seed = torch.randint(0, 2**32 - 1, (1,)).item()
        
        generator = torch.Generator("cpu").manual_seed(seed)
        progress(0.5, desc="ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
        
        # ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ìƒì„±
        result = pipe(
            prompt=prompt,
            negative_prompt=negative_prompt,
            control_mask=mask_image,
            control_image=input_image,
            height=height,
            width=width,
            num_inference_steps=int(num_inference_steps),
            guidance_scale=float(guidance_scale),
            controlnet_conditioning_scale=float(controlnet_conditioning_scale),
            generator=generator,
        )
      
        progress(0.9, desc="ê²°ê³¼ ì €ì¥ ì¤‘...")
        enhanced_image = result.images[0]
        
        # ê³ í’ˆì§ˆë¡œ ì €ì¥
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"enhanced_inpainting_{timestamp}.png"
        enhanced_image.save(filename, optimize=True, quality=95)
        
        progress(1.0, desc="ì™„ë£Œ!")
        
        status_message = f"""âœ… ì´ë¯¸ì§€ í™”ì§ˆ ê°œì„  ì™„ë£Œ!
ğŸ“ ì €ì¥ íŒŒì¼: {filename}
ğŸ“ í¬ê¸°: {width}x{height}
ğŸ­ ë§ˆìŠ¤í¬ íƒ€ì…: {mask_type}
ğŸ² ì‹œë“œ: {seed}
âš™ï¸ ì¶”ë¡  ìŠ¤í…: {num_inference_steps}
ğŸ¯ ê°€ì´ë˜ìŠ¤: {guidance_scale}"""
        
        return enhanced_image, mask_image, status_message
        
    except Exception as e:
        return None, None, f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±
with gr.Blocks(title="SD3 ControlNet Inpainting í™”ì§ˆ ê°œì„ ê¸°", theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ¨ SD3 ControlNet Inpainting í™”ì§ˆ ê°œì„ ê¸°
    Stable Diffusion 3 ControlNetì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì˜ íŠ¹ì • ë¶€ë¶„ì„ ê³ í’ˆì§ˆë¡œ ì¸í˜ì¸íŒ…í•©ë‹ˆë‹¤.
    """)
    
    with gr.Row():
        with gr.Column(scale=1):
            # ì…ë ¥ ì´ë¯¸ì§€
            input_image = gr.Image(
                label="ğŸ“· ì…ë ¥ ì´ë¯¸ì§€",
                type="pil",
                height=500,
                value="default.jpg"
            )
            
            # í”„ë¡¬í”„íŠ¸
            prompt = gr.Textbox(
                label="âœ¨ í”„ë¡¬í”„íŠ¸",
                placeholder="photorealistic, ultra high definition, 8k resolution, masterpiece, best quality",
                lines=3,
                value="photorealistic, ultra high definition, 8k resolution, masterpiece, best quality"
            )
            
            negative_prompt = gr.Textbox(
                label="ğŸš« ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸",
                lines=3,
                value="deformed, distorted, disfigured, poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, mutated hands and fingers, disconnected limbs, mutation, mutated, ugly, disgusting, blurry, amputation, NSFW, low quality, worst quality, jpeg artifacts"
            )
            
        with gr.Column(scale=1):
            # ë§ˆìŠ¤í¬ ì„¤ì •
            with gr.Group():
                gr.Markdown("### ğŸ­ ë§ˆìŠ¤í¬ ì„¤ì •")
                gr.Markdown("""
                **ë§ˆìŠ¤í¬**ëŠ” ì´ë¯¸ì§€ì—ì„œ ë³€ê²½í•  ì˜ì—­ì„ ì§€ì •í•©ë‹ˆë‹¤.
                - **ì¤‘ì•™ ì›í˜•**: ì´ë¯¸ì§€ ì¤‘ì•™ì— ì›í˜• ì˜ì—­ì„ ì„ íƒ
                - **ì—£ì§€ ê¸°ë°˜**: ì´ë¯¸ì§€ì˜ ê²½ê³„ì„ ì„ ê°ì§€í•˜ì—¬ ìë™ ì„ íƒ
                - **ì „ì²´ ì˜ì—­**: ì´ë¯¸ì§€ ì „ì²´ë¥¼ ë³€ê²½ ëŒ€ìƒìœ¼ë¡œ ì„¤ì •
                """)
                
                mask_type = gr.Radio(
                    choices=["ì¤‘ì•™ ì›í˜•", "ì—£ì§€ ê¸°ë°˜", "ì „ì²´ ì˜ì—­"],
                    value="ì¤‘ì•™ ì›í˜•",
                    label="ë§ˆìŠ¤í¬ íƒ€ì…"
                )
                
                mask_size = gr.Slider(
                    minimum=0.1,
                    maximum=0.8,
                    value=0.3,
                    step=0.05,
                    label="ğŸ” ë§ˆìŠ¤í¬ í¬ê¸°/ê°•ë„",
                    info="ì¤‘ì•™ ì›í˜•: ì›ì˜ í¬ê¸° (0.1=ì‘ìŒ, 0.8=í¼) | ì—£ì§€ ê¸°ë°˜: ê°ì§€ ë¯¼ê°ë„ (0.1=ì„¸ë°€, 0.8=í° ê²½ê³„ë§Œ)"
                )
            
            # ìƒì„± ì„¤ì •
            with gr.Group():
                gr.Markdown("### âš™ï¸ ìƒì„± ì„¤ì •")
                gr.Markdown("""
                **ìƒì„± í’ˆì§ˆê³¼ ì†ë„ë¥¼ ì¡°ì ˆí•˜ëŠ” í•µì‹¬ ë§¤ê°œë³€ìˆ˜ë“¤ì…ë‹ˆë‹¤.**
                """)
                
                num_inference_steps = gr.Slider(
                    minimum=20,
                    maximum=100,
                    value=50,
                    step=1,
                    label="ğŸ”„ ì¶”ë¡  ìŠ¤í… (ë†’ì„ìˆ˜ë¡ ê³ í’ˆì§ˆ, ëŠë¦¼)",
                    info="AIê°€ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ë°˜ë³µ íšŸìˆ˜. 20=ë¹ ë¦„/ì €í’ˆì§ˆ, 50=ê· í˜•, 100=ëŠë¦¼/ê³ í’ˆì§ˆ"
                )
                
                guidance_scale = gr.Slider(
                    minimum=1.0,
                    maximum=20.0,
                    value=7.5,
                    step=0.1,
                    label="ğŸ¯ ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼ (í”„ë¡¬í”„íŠ¸ ì¶©ì‹¤ë„)",
                    info="í”„ë¡¬í”„íŠ¸ë¥¼ ì–¼ë§ˆë‚˜ ì •í™•íˆ ë”°ë¥¼ì§€ ê²°ì •. 1.0=ììœ ë¡œìš´ ìƒì„±, 7.5=ê· í˜•, 15.0+=í”„ë¡¬í”„íŠ¸ ì—„ê²© ì¤€ìˆ˜"
                )
                
                controlnet_conditioning_scale = gr.Slider(
                    minimum=0.0,
                    maximum=2.0,
                    value=0.95,
                    step=0.05,
                    label="ğŸ® ControlNet ê°•ë„",
                    info="ì›ë³¸ ì´ë¯¸ì§€ êµ¬ì¡° ìœ ì§€ ì •ë„. 0.0=ì™„ì „ ìƒˆë¡œìš´ ì´ë¯¸ì§€, 1.0=ì›ë³¸ êµ¬ì¡° ìœ ì§€, 2.0=ê³¼ë„í•œ ìœ ì§€"
                )
                
                target_size = gr.Slider(
                    minimum=512,
                    maximum=1536,
                    value=1024,
                    step=64,
                    label="ğŸ“ ëª©í‘œ í¬ê¸°",
                    info="ìƒì„±ë  ì´ë¯¸ì§€ì˜ ê¸´ ìª½ í¬ê¸°(í”½ì…€). 512=ë¹ ë¦„/ì €í•´ìƒë„, 1024=ê· í˜•, 1536=ëŠë¦¼/ê³ í•´ìƒë„"
                )

                seed = gr.Number(
                    label="ğŸ² ì‹œë“œ (-1: ëœë¤)",
                    value=-1,
                    precision=0,
                    info="ë™ì¼í•œ ì‹œë“œë¡œ ê°™ì€ ê²°ê³¼ ì¬í˜„ ê°€ëŠ¥. -1=ë§¤ë²ˆ ë‹¤ë¥¸ ê²°ê³¼, ê³ ì •ê°’=ë™ì¼ ê²°ê³¼"
                )
            
            generate_btn = gr.Button(
                "ğŸš€ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ìƒì„±",
                variant="primary",
                size="lg"
            )
    
    with gr.Row():
        with gr.Column():
            output_image = gr.Image(
                label="âœ¨ ê°œì„ ëœ ì´ë¯¸ì§€",
                type="pil",
                height=500
            )
            
        with gr.Column():
            generated_mask = gr.Image(
                label="ğŸ­ ìƒì„±ëœ ë§ˆìŠ¤í¬",
                type="pil",
                height=500
            )
    
    with gr.Row():
        status_text = gr.Textbox(
            label="ğŸ“Š ìƒì„± ì •ë³´",
            lines=6,
            max_lines=10
        )
    
    # ì´ë²¤íŠ¸ ë°”ì¸ë”©
    generate_btn.click(
        fn=enhance_image_quality,
        inputs=[
            input_image,
            prompt,
            negative_prompt,
            mask_type,
            mask_size,
            num_inference_steps,
            guidance_scale,
            controlnet_conditioning_scale,
            seed,
            target_size
        ],
        outputs=[output_image, generated_mask, status_text]
    )

# ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰
if __name__ == "__main__":
    demo.launch(
        inbrowser=True,
    )