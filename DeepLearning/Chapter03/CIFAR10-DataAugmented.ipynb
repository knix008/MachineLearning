{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95382fe7-2516-4833-8b21-93de07a76da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 32, 32, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 32, 32, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 8, 8, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 8, 8, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                20490     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "782/782 [==============================] - 104s 131ms/step - loss: 2.1019 - accuracy: 0.3588 - val_loss: 1.3403 - val_accuracy: 0.5249\n",
      "Epoch 2/50\n",
      "782/782 [==============================] - 113s 145ms/step - loss: 1.5849 - accuracy: 0.4938 - val_loss: 1.5024 - val_accuracy: 0.5257\n",
      "Epoch 3/50\n",
      "782/782 [==============================] - 115s 147ms/step - loss: 1.3862 - accuracy: 0.5509 - val_loss: 1.1659 - val_accuracy: 0.6237\n",
      "Epoch 4/50\n",
      "782/782 [==============================] - 118s 151ms/step - loss: 1.2550 - accuracy: 0.5905 - val_loss: 1.2486 - val_accuracy: 0.6125\n",
      "Epoch 5/50\n",
      "782/782 [==============================] - 109s 140ms/step - loss: 1.1569 - accuracy: 0.6172 - val_loss: 1.1302 - val_accuracy: 0.6455\n",
      "Epoch 6/50\n",
      "782/782 [==============================] - 108s 138ms/step - loss: 1.0700 - accuracy: 0.6377 - val_loss: 0.9630 - val_accuracy: 0.6802\n",
      "Epoch 7/50\n",
      "782/782 [==============================] - 120s 153ms/step - loss: 1.0124 - accuracy: 0.6568 - val_loss: 1.0442 - val_accuracy: 0.6603\n",
      "Epoch 8/50\n",
      "782/782 [==============================] - 111s 142ms/step - loss: 0.9578 - accuracy: 0.6725 - val_loss: 0.9207 - val_accuracy: 0.7088\n",
      "Epoch 9/50\n",
      "782/782 [==============================] - 109s 139ms/step - loss: 0.9179 - accuracy: 0.6853 - val_loss: 0.8865 - val_accuracy: 0.7148\n",
      "Epoch 10/50\n",
      "782/782 [==============================] - 114s 145ms/step - loss: 0.8844 - accuracy: 0.6932 - val_loss: 0.7291 - val_accuracy: 0.7496\n",
      "Epoch 11/50\n",
      "782/782 [==============================] - 116s 149ms/step - loss: 0.8570 - accuracy: 0.7058 - val_loss: 0.7383 - val_accuracy: 0.7489\n",
      "Epoch 12/50\n",
      "782/782 [==============================] - 114s 146ms/step - loss: 0.8354 - accuracy: 0.7129 - val_loss: 0.8217 - val_accuracy: 0.7441\n",
      "Epoch 13/50\n",
      "782/782 [==============================] - 115s 148ms/step - loss: 0.8076 - accuracy: 0.7236 - val_loss: 0.8331 - val_accuracy: 0.7372\n",
      "Epoch 14/50\n",
      "782/782 [==============================] - 111s 142ms/step - loss: 0.7887 - accuracy: 0.7275 - val_loss: 0.8564 - val_accuracy: 0.7382\n",
      "Epoch 15/50\n",
      "782/782 [==============================] - 109s 139ms/step - loss: 0.7753 - accuracy: 0.7333 - val_loss: 0.6689 - val_accuracy: 0.7779\n",
      "Epoch 16/50\n",
      "782/782 [==============================] - 110s 140ms/step - loss: 0.7575 - accuracy: 0.7370 - val_loss: 0.7923 - val_accuracy: 0.7531\n",
      "Epoch 17/50\n",
      "782/782 [==============================] - 110s 141ms/step - loss: 0.7391 - accuracy: 0.7447 - val_loss: 0.7407 - val_accuracy: 0.7629\n",
      "Epoch 18/50\n",
      "782/782 [==============================] - 112s 143ms/step - loss: 0.7247 - accuracy: 0.7502 - val_loss: 0.7835 - val_accuracy: 0.7615\n",
      "Epoch 19/50\n",
      "782/782 [==============================] - 118s 150ms/step - loss: 0.7149 - accuracy: 0.7544 - val_loss: 0.6270 - val_accuracy: 0.7945\n",
      "Epoch 20/50\n",
      "782/782 [==============================] - 110s 141ms/step - loss: 0.7098 - accuracy: 0.7550 - val_loss: 0.6197 - val_accuracy: 0.8015\n",
      "Epoch 21/50\n",
      "782/782 [==============================] - 110s 140ms/step - loss: 0.6974 - accuracy: 0.7588 - val_loss: 0.7044 - val_accuracy: 0.7771\n",
      "Epoch 22/50\n",
      "782/782 [==============================] - 111s 142ms/step - loss: 0.6901 - accuracy: 0.7602 - val_loss: 0.6394 - val_accuracy: 0.7938\n",
      "Epoch 23/50\n",
      "782/782 [==============================] - 115s 147ms/step - loss: 0.6748 - accuracy: 0.7675 - val_loss: 0.6255 - val_accuracy: 0.7964\n",
      "Epoch 24/50\n",
      "782/782 [==============================] - 114s 145ms/step - loss: 0.6707 - accuracy: 0.7676 - val_loss: 0.6920 - val_accuracy: 0.7859\n",
      "Epoch 25/50\n",
      "782/782 [==============================] - 113s 145ms/step - loss: 0.6591 - accuracy: 0.7735 - val_loss: 0.5827 - val_accuracy: 0.8130\n",
      "Epoch 26/50\n",
      "782/782 [==============================] - 111s 142ms/step - loss: 0.6559 - accuracy: 0.7742 - val_loss: 0.6701 - val_accuracy: 0.7878\n",
      "Epoch 27/50\n",
      "782/782 [==============================] - 116s 149ms/step - loss: 0.6533 - accuracy: 0.7765 - val_loss: 0.6042 - val_accuracy: 0.8101\n",
      "Epoch 28/50\n",
      "782/782 [==============================] - 115s 147ms/step - loss: 0.6401 - accuracy: 0.7782 - val_loss: 0.5846 - val_accuracy: 0.8070\n",
      "Epoch 29/50\n",
      "782/782 [==============================] - 123s 158ms/step - loss: 0.6401 - accuracy: 0.7803 - val_loss: 0.5766 - val_accuracy: 0.8139\n",
      "Epoch 30/50\n",
      "782/782 [==============================] - 123s 157ms/step - loss: 0.6326 - accuracy: 0.7824 - val_loss: 0.5424 - val_accuracy: 0.8231\n",
      "Epoch 31/50\n",
      "782/782 [==============================] - 117s 149ms/step - loss: 0.6251 - accuracy: 0.7837 - val_loss: 0.5628 - val_accuracy: 0.8162\n",
      "Epoch 32/50\n",
      "782/782 [==============================] - 115s 146ms/step - loss: 0.6225 - accuracy: 0.7851 - val_loss: 0.6108 - val_accuracy: 0.8006\n",
      "Epoch 33/50\n",
      "782/782 [==============================] - 116s 148ms/step - loss: 0.6163 - accuracy: 0.7877 - val_loss: 0.6025 - val_accuracy: 0.8110\n",
      "Epoch 34/50\n",
      "782/782 [==============================] - 111s 142ms/step - loss: 0.6113 - accuracy: 0.7895 - val_loss: 0.5686 - val_accuracy: 0.8186\n",
      "Epoch 35/50\n",
      "782/782 [==============================] - 110s 141ms/step - loss: 0.6110 - accuracy: 0.7896 - val_loss: 0.6215 - val_accuracy: 0.8017\n",
      "Epoch 36/50\n",
      "782/782 [==============================] - 111s 142ms/step - loss: 0.6081 - accuracy: 0.7920 - val_loss: 0.5148 - val_accuracy: 0.8326\n",
      "Epoch 37/50\n",
      "782/782 [==============================] - 110s 141ms/step - loss: 0.5975 - accuracy: 0.7943 - val_loss: 0.6002 - val_accuracy: 0.8088\n",
      "Epoch 38/50\n",
      "782/782 [==============================] - 110s 140ms/step - loss: 0.6002 - accuracy: 0.7930 - val_loss: 0.5499 - val_accuracy: 0.8268\n",
      "Epoch 39/50\n",
      "782/782 [==============================] - 111s 141ms/step - loss: 0.5862 - accuracy: 0.7985 - val_loss: 0.5573 - val_accuracy: 0.8239\n",
      "Epoch 40/50\n",
      "782/782 [==============================] - 110s 141ms/step - loss: 0.5866 - accuracy: 0.7977 - val_loss: 0.4825 - val_accuracy: 0.8399\n",
      "Epoch 41/50\n",
      "782/782 [==============================] - 110s 141ms/step - loss: 0.5828 - accuracy: 0.7984 - val_loss: 0.5550 - val_accuracy: 0.8218\n",
      "Epoch 42/50\n",
      "782/782 [==============================] - 110s 141ms/step - loss: 0.5789 - accuracy: 0.7994 - val_loss: 0.5443 - val_accuracy: 0.8278\n",
      "Epoch 43/50\n",
      "782/782 [==============================] - 110s 140ms/step - loss: 0.5769 - accuracy: 0.8018 - val_loss: 0.5689 - val_accuracy: 0.8179\n",
      "Epoch 44/50\n",
      "782/782 [==============================] - 111s 142ms/step - loss: 0.5750 - accuracy: 0.8023 - val_loss: 0.6137 - val_accuracy: 0.8053\n",
      "Epoch 45/50\n",
      "782/782 [==============================] - 113s 144ms/step - loss: 0.5740 - accuracy: 0.8020 - val_loss: 0.5128 - val_accuracy: 0.8346\n",
      "Epoch 46/50\n",
      "782/782 [==============================] - 110s 141ms/step - loss: 0.5727 - accuracy: 0.8019 - val_loss: 0.4930 - val_accuracy: 0.8427\n",
      "Epoch 47/50\n",
      "782/782 [==============================] - 111s 142ms/step - loss: 0.5656 - accuracy: 0.8053 - val_loss: 0.5387 - val_accuracy: 0.8233\n",
      "Epoch 48/50\n",
      "782/782 [==============================] - 111s 141ms/step - loss: 0.5625 - accuracy: 0.8070 - val_loss: 0.5672 - val_accuracy: 0.8269\n",
      "Epoch 49/50\n",
      "782/782 [==============================] - 110s 141ms/step - loss: 0.5665 - accuracy: 0.8038 - val_loss: 0.5348 - val_accuracy: 0.8306\n",
      "Epoch 50/50\n",
      "782/782 [==============================] - 111s 142ms/step - loss: 0.5604 - accuracy: 0.8079 - val_loss: 0.5134 - val_accuracy: 0.8341\n",
      "79/79 [==============================] - 5s 61ms/step - loss: 0.5134 - accuracy: 0.8341\n",
      "\n",
      "Test result: 83.410 loss: 0.513\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, regularizers, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    " \n",
    "EPOCHS=50\n",
    "NUM_CLASSES = 10\n",
    "    \n",
    "\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    " \n",
    "    #normalize \n",
    "    mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "    std = np.std(x_train,axis=(0,1,2,3))\n",
    "    x_train = (x_train-mean)/(std+1e-7)\n",
    "    x_test = (x_test-mean)/(std+1e-7)\n",
    " \n",
    "    y_train =  tf.keras.utils.to_categorical(y_train,NUM_CLASSES)\n",
    "    y_test =  tf.keras.utils.to_categorical(y_test,NUM_CLASSES)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def build_model(): \n",
    "    model = models.Sequential()\n",
    "    \n",
    "    #1st blocl\n",
    "    model.add(layers.Conv2D(32, (3,3), padding='same', \n",
    "        input_shape=x_train.shape[1:], activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    #2nd block\n",
    "    model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    #3d block \n",
    "    model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "\n",
    "    #dense  \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
    "    return model\n",
    " \n",
    "\n",
    "(x_train, y_train, x_test, y_test) = load_data()\n",
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "            optimizer='RMSprop', \n",
    "            metrics=['accuracy'])\n",
    "\n",
    "#image augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)\n",
    " \n",
    "#train\n",
    "batch_size = 64\n",
    "model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,validation_data=(x_test,y_test))\n",
    "\n",
    "#save to disk\n",
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights('model.h5') \n",
    "\n",
    "#test\n",
    "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
    "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b85487a-200e-4aab-8be4-607f531783a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
