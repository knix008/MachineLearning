import torch
from diffusers import FluxControlNetModel
from diffusers.pipelines import FluxControlNetPipeline
import datetime
import gradio as gr
from PIL import Image

# ëª¨ë¸ ë¡œë”©
controlnet = FluxControlNetModel.from_pretrained(
    "jasperai/Flux.1-dev-Controlnet-Upscaler", torch_dtype=torch.bfloat16
)
pipe = FluxControlNetPipeline.from_pretrained(
    "black-forest-labs/FLUX.1-dev", controlnet=controlnet, torch_dtype=torch.bfloat16
)

pipe.enable_model_cpu_offload()
pipe.enable_sequential_cpu_offload()
pipe.enable_attention_slicing(1)
print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

def resize_image_keep_aspect(image, max_size=512):
    """ì´ë¯¸ì§€ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©´ì„œ ìµœëŒ€ í¬ê¸° ì œí•œ"""
    w, h = image.size
    if w <= max_size and h <= max_size:
        return image
    
    # ë¹„ìœ¨ ê³„ì‚°
    if w > h:
        new_w = max_size
        new_h = int(h * max_size / w)
    else:
        new_h = max_size
        new_w = int(w * max_size / h)
    
    return image.resize((new_w, new_h), Image.LANCZOS)

def upscale_image(
    input_image,
    upscale_factor,
    guidance_scale,
    num_inference_steps,
    controlnet_conditioning_scale,
    prompt,
):
    if input_image is None:
        return None, "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”."
    
    # ì…ë ¥ ì´ë¯¸ì§€ë¥¼ 512 ì´í•˜ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ë¹„ìœ¨ ìœ ì§€)
    resized_input = resize_image_keep_aspect(input_image, max_size=512)
    w, h = resized_input.size
    
    # ì—…ìŠ¤ì¼€ì¼ ì ìš©
    new_w = int(w * upscale_factor)
    new_h = int(h * upscale_factor)
    resized_image = resized_input.resize((new_w, new_h), Image.LANCZOS)

    try:
        image = pipe(
            prompt=prompt,
            control_image=resized_image,
            controlnet_conditioning_scale=controlnet_conditioning_scale,
            num_inference_steps=int(num_inference_steps),
            guidance_scale=float(guidance_scale),
            height=new_h,
            width=new_w,
        ).images[0]
        filename = f"Flux1-Upscaled-{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.png"
        image.save(filename)
        info = f"ìƒì„± ì™„ë£Œ!\nì €ì¥ íŒŒì¼: {filename}\nì…ë ¥ í¬ê¸°: {input_image.size[0]}x{input_image.size[1]}\në¦¬ì‚¬ì´ì¦ˆ í›„: {w}x{h}\nìµœì¢… í¬ê¸°: {new_w}x{new_h}\nê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼: {guidance_scale}\nì¶”ë¡  ìŠ¤í…: {num_inference_steps}\nì»¨ë””ì…”ë‹ ìŠ¤ì¼€ì¼: {controlnet_conditioning_scale}"
        return image, info
    except Exception as e:
        return None, f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

with gr.Blocks(title="FLUX.1 ControlNet ì—…ìŠ¤ì¼€ì¼ëŸ¬") as demo:
    gr.Markdown("# ğŸ–¼ï¸ FLUX.1 ControlNet ì—…ìŠ¤ì¼€ì¼ëŸ¬")
    gr.Markdown("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê³ , ë‹¤ì–‘í•œ ì„¤ì •ìœ¼ë¡œ ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì„¸ìš”!")

    with gr.Row():
        with gr.Column(scale=1):
            input_image = gr.Image(
                label="ì…ë ¥ ì´ë¯¸ì§€",
                type="pil",
                sources=["upload", "clipboard"],
                height=400,
                value="default.jpg",  # ê¸°ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ (ì˜ˆì‹œìš©)
            )
            prompt_input = gr.Textbox(
                label="í”„ë¡¬í”„íŠ¸ (ì„ íƒ)",
                placeholder="ì´ë¯¸ì§€ì— ì ìš©í•  ìŠ¤íƒ€ì¼ì´ë‚˜ ì„¤ëª…ì„ ì…ë ¥í•˜ì„¸ìš”...",
                value="8k, high detail, realistic, high quality, masterpiece, best quality, detailed, intricate, smooth, cinematic lighting",
                lines=2,
            )
            upscale_slider = gr.Slider(
                minimum=1,
                maximum=8,
                value=4,
                step=1,
                label="ì—…ìŠ¤ì¼€ì¼ ë°°ìœ¨",
                info="ì´ë¯¸ì§€ë¥¼ ëª‡ ë°°ë¡œ í™•ëŒ€í• ì§€ ì„ íƒ (ì˜ˆ: 4ë°°)",
            )
            guidance_slider = gr.Slider(
                minimum=1.0,
                maximum=10.0,
                value=3.5,
                step=0.1,
                label="ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼",
                info="í”„ë¡¬í”„íŠ¸ ì¤€ìˆ˜ ì •ë„. ë†’ì„ìˆ˜ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ ë” ì •í™•íˆ ë”°ë¦„.",
            )
            steps_slider = gr.Slider(
                minimum=10,
                maximum=50,
                value=28,
                step=1,
                label="ì¶”ë¡  ìŠ¤í… ìˆ˜",
                info="ì´ë¯¸ì§€ ìƒì„± ë‹¨ê³„ ìˆ˜. ë†’ì„ìˆ˜ë¡ í’ˆì§ˆì´ í–¥ìƒë˜ì§€ë§Œ ìƒì„± ì‹œê°„ì´ ëŠ˜ì–´ë‚¨.",
            )
            conditioning_slider = gr.Slider(
                minimum=0.1,
                maximum=1.0,
                value=0.6,
                step=0.05,
                label="ì»¨ë””ì…”ë‹ ìŠ¤ì¼€ì¼",
                info="ControlNetì˜ ì˜í–¥ë ¥. ë†’ì„ìˆ˜ë¡ ì…ë ¥ ì´ë¯¸ì§€ì— ë” ê°•í•˜ê²Œ ë°˜ì˜ë¨.",
            )
            generate_btn = gr.Button("ğŸ–¼ï¸ ì—…ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€ ìƒì„±", variant="primary", size="lg")

            with gr.Accordion("ğŸ“š ì„¤ì • ê°€ì´ë“œ", open=False):
                gr.Markdown(
                    """
                    ### ì£¼ìš” ì„¤ì • ì„¤ëª…

                    **ì—…ìŠ¤ì¼€ì¼ ë°°ìœ¨**  
                    - ì´ë¯¸ì§€ë¥¼ ëª‡ ë°°ë¡œ í™•ëŒ€í• ì§€ ì„ íƒí•©ë‹ˆë‹¤.  
                    - ë„ˆë¬´ í¬ê²Œ í•˜ë©´ ë©”ëª¨ë¦¬ ë¶€ì¡±ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

                    **ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼**  
                    - í”„ë¡¬í”„íŠ¸ë¥¼ ì–¼ë§ˆë‚˜ ì—„ê²©í•˜ê²Œ ë”°ë¥¼ì§€ ê²°ì •í•©ë‹ˆë‹¤.  
                    - ë†’ì„ìˆ˜ë¡ í”„ë¡¬í”„íŠ¸ì— ë” ê°€ê¹Œìš´ ê²°ê³¼ê°€ ë‚˜ì˜¤ì§€ë§Œ ì°½ì˜ì„±ì´ ì¤„ì–´ë“­ë‹ˆë‹¤.

                    **ì¶”ë¡  ìŠ¤í… ìˆ˜**  
                    - ì´ë¯¸ì§€ ìƒì„± ë‹¨ê³„ ìˆ˜ì…ë‹ˆë‹¤.  
                    - ë†’ì„ìˆ˜ë¡ í’ˆì§ˆì´ ì¢‹ì•„ì§€ì§€ë§Œ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤.

                    **ì»¨ë””ì…”ë‹ ìŠ¤ì¼€ì¼**  
                    - ControlNetì˜ ì˜í–¥ë ¥ì…ë‹ˆë‹¤.  
                    - ë†’ì„ìˆ˜ë¡ ì…ë ¥ ì´ë¯¸ì§€ì˜ êµ¬ì¡°ë¥¼ ë” ê°•í•˜ê²Œ ë°˜ì˜í•©ë‹ˆë‹¤.

                    **í”„ë¡¬í”„íŠ¸**  
                    - ì´ë¯¸ì§€ì— ì ìš©í•  ìŠ¤íƒ€ì¼ì´ë‚˜ ì„¤ëª…ì„ ì…ë ¥í•˜ì„¸ìš”.  
                    - ì˜ˆì‹œ: "anime style, vibrant colors, high detail"
                    """
                )

        with gr.Column(scale=1):
            output_image = gr.Image(label="ì—…ìŠ¤ì¼€ì¼ ê²°ê³¼", type="pil", height=512)
            info_output = gr.Textbox(label="ìƒì„± ì •ë³´", lines=4, interactive=False)

    generate_btn.click(
        fn=upscale_image,
        inputs=[
            input_image,
            upscale_slider,
            guidance_slider,
            steps_slider,
            conditioning_slider,
            prompt_input,
        ],
        outputs=[output_image, info_output],
    )

if __name__ == "__main__":
    demo.launch(inbrowser=True)
