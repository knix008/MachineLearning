import torch
import gradio as gr
import time
from diffusers import FluxKontextPipeline
from PIL import Image

# Dependency!!! :
# You need to install the diffusers with the following command:
# pip install git+https://github.com/huggingface/diffusers.git

# Load model with memory optimizations
print("ëª¨ë¸ì„ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤...")
pipe = FluxKontextPipeline.from_pretrained(
    "black-forest-labs/FLUX.1-Kontext-dev", torch_dtype=torch.bfloat16
)

# Enable multiple memory optimizations
pipe.enable_model_cpu_offload()  # Offload model to CPU when not in use
pipe.enable_sequential_cpu_offload()  # More aggressive CPU offloading
pipe.enable_attention_slicing(1)  # Slice attention computation
pipe.enable_vae_slicing()  # Slice VAE computation
print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")


def generate_image(
    prompt,
    input_image,
    width,
    height,
    guidance_scale,
    num_inference_steps,
    max_sequence_length,
    seed,
    progress=gr.Progress(),
):
    """ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ (FluxKontext ì „ìš© - Image-to-Imageë§Œ ì§€ì›)"""

    # â­ ì…ë ¥ ì´ë¯¸ì§€ í•„ìˆ˜ ì²´í¬
    if input_image is None:
        error_text = "âŒ FluxKontextëŠ” Image-to-Image ì „ìš© ëª¨ë¸ì…ë‹ˆë‹¤.\n\nğŸ“¸ ë³€í™˜í•  ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!\n\nì‚¬ìš©ë²•:\n1. ì¢Œì¸¡ ìƒë‹¨ì— ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”\n2. ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹ì„ ì„ íƒí•˜ì„¸ìš”\n3. í•„ìš”ì‹œ í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”\n4. 'ğŸ¨ ì´ë¯¸ì§€ ìƒì„±' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”"
        return None, error_text

    start_time = time.time()

    # Progress bar ì‹œì‘
    progress(0.1, desc="ğŸ¨ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘...")

    # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° ì €ì¥
    original_width, original_height = input_image.size
    original_ratio = original_width / original_height

    progress(0.2, desc="ğŸ“ ì›ë³¸ í¬ê¸° ìœ ì§€ ì„¤ì • ì¤‘...")

    # ì‹œë“œ ì„¤ì •
    if seed == -1:
        seed = torch.randint(0, 2**32 - 1, (1,)).item()

    generator = torch.Generator("cpu").manual_seed(seed)

    try:
        progress(0.3, desc="ğŸ–¼ï¸ ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘...")

        # â­ ë¬´ì¡°ê±´ ì›ë³¸ í¬ê¸° ê·¸ëŒ€ë¡œ ì‚¬ìš©
        input_image_for_processing = input_image.convert("RGB")
        
        progress(0.5, desc="ğŸ§  AI ëª¨ë¸ ì²˜ë¦¬ ì¤‘ (ì›ë³¸ í¬ê¸° ìœ ì§€)...")
        
        # â­ ì›ë³¸ í¬ê¸° ê·¸ëŒ€ë¡œ ëª¨ë¸ì— ì „ë‹¬
        image = pipe(
            prompt=prompt,
            image=input_image_for_processing,
            guidance_scale=guidance_scale,
            num_inference_steps=int(num_inference_steps),
            generator=generator,
        ).images[0]

        progress(0.9, desc="ğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")

        end_time = time.time()
        generation_time = end_time - start_time

        # ì´ë¯¸ì§€ ì €ì¥ (ê³ í’ˆì§ˆ)
        timestamp = int(time.time())
        filename = f"flux_enhanced_{timestamp}.png"
        image.save(filename, optimize=True, quality=95)

        # ìƒì„±ëœ ì´ë¯¸ì§€ í¬ê¸° ì •ë³´
        generated_width, generated_height = image.size
        final_ratio = generated_width / generated_height

        # â­ í¬ê¸° ìœ ì§€ ì •ë³´
        size_info = f"\nğŸ“ ì´ë¯¸ì§€ í¬ê¸°: {original_width}x{original_height} â†’ {generated_width}x{generated_height}"
        size_info += f"\nğŸ“ ë¹„ìœ¨ ìœ ì§€: {original_ratio:.3f} â†’ {final_ratio:.3f} (ì°¨ì´: {abs(original_ratio - final_ratio):.3f})"
        
        # í¬ê¸° ë³€í™” ì •ë³´
        if generated_width == original_width and generated_height == original_height:
            size_info += f"\nâœ… ì›ë³¸ í¬ê¸° ì™„ì „ ìœ ì§€"
        else:
            size_change_w = abs(original_width - generated_width)
            size_change_h = abs(original_height - generated_height)
            size_info += f"\nğŸ“ í¬ê¸° ë³€í™”: ê°€ë¡œ {size_change_w}px, ì„¸ë¡œ {size_change_h}px"

        progress(1.0, desc="âœ… ì™„ë£Œ!")

        info_text = f"âœ… ì´ë¯¸ì§€ ë³€í™˜ ì™„ë£Œ!\nâ±ï¸ ì²˜ë¦¬ ì‹œê°„: {generation_time:.2f}ì´ˆ\nğŸ² ì‹œë“œ: {seed}\nğŸ’¾ ì €ì¥ íŒŒì¼: {filename}\nğŸ¨ ê°€ì´ë˜ìŠ¤: {guidance_scale} | âš¡ ìŠ¤í…: {num_inference_steps}{size_info}\n\nğŸ“ ì‚¬ìš©ëœ í”„ë¡¬í”„íŠ¸:\n{prompt[:100]}..."

        return image, info_text

    except Exception as e:
        progress(1.0, desc="âŒ ì˜¤ë¥˜ ë°œìƒ")
        error_text = f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n\nğŸ’¡ í•´ê²° ë°©ë²•:\n- ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹ì„ ì‹œë„í•´ë³´ì„¸ìš”\n- ì´ë¯¸ì§€ íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”\n- í”„ë¡¬í”„íŠ¸ë¥¼ ë” ê°„ë‹¨í•˜ê²Œ ì‘ì„±í•´ë³´ì„¸ìš”"
        return None, error_text


# í”„ë¦¬ì…‹ ì„ íƒ ì‹œ ìë™ ì„¤ì • ì ìš©
def apply_preset_settings(preset_name):
    """ì„ íƒí•œ í”„ë¦¬ì…‹ì— ë”°ë¼ ì„¤ì •ê°’ ìë™ ì¡°ì •"""
    preset = STYLE_PRESETS.get(preset_name, STYLE_PRESETS["ê¸°ë³¸"])
    return preset["guidance_scale"], preset["num_inference_steps"]


# â­ ì´ë¯¸ì§€ ë¹„ìœ¨ ë¶„ì„ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def get_aspect_ratio_info(image):
    """ì´ë¯¸ì§€ì˜ ë¹„ìœ¨ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ë°˜í™˜"""
    if image is None:
        return "ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    w, h = image.size
    ratio = w / h
    
    # ì¼ë°˜ì ì¸ ë¹„ìœ¨ ë§¤ì¹­
    if abs(ratio - 1.0) < 0.05:
        ratio_name = "ì •ì‚¬ê°í˜• (1:1)"
    elif abs(ratio - 4/3) < 0.05:
        ratio_name = "í‘œì¤€ (4:3)"
    elif abs(ratio - 16/9) < 0.05:
        ratio_name = "ì™€ì´ë“œ (16:9)"
    elif abs(ratio - 3/2) < 0.05:
        ratio_name = "ì‚¬ì§„ (3:2)"
    elif abs(ratio - 9/16) < 0.05:
        ratio_name = "ì„¸ë¡œí˜• (9:16)"
    elif abs(ratio - 2/3) < 0.05:
        ratio_name = "ì„¸ë¡œí˜• (2:3)"
    elif abs(ratio - 5/4) < 0.05:
        ratio_name = "ì •ì‚¬ê°í˜•ì— ê°€ê¹Œìš´ (5:4)"
    else:
        ratio_name = f"ì‚¬ìš©ì ì •ì˜ ({ratio:.2f}:1)"
    
    # íŒŒì¼ í¬ê¸° ì˜ˆìƒ ì •ë³´ ì¶”ê°€
    megapixels = (w * h) / 1000000
    size_category = ""
    if megapixels < 1:
        size_category = "ì†Œí˜•"
    elif megapixels < 5:
        size_category = "ì¤‘í˜•"
    elif megapixels < 20:
        size_category = "ëŒ€í˜•"
    else:
        size_category = "ì´ˆëŒ€í˜•"
    
    return f"ğŸ“ {w}Ã—{h} | {ratio_name} | {megapixels:.1f}MP ({size_category})"


def show_image_info(image):
    """ì…ë ¥ ì´ë¯¸ì§€ì˜ ì •ë³´ë¥¼ í‘œì‹œ"""
    if image is None:
        return "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
    return get_aspect_ratio_info(image)


# â­ FluxKontext ëª¨ë¸ìš© ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹ (ì¸ë¬¼ í™”ì§ˆ ìµœì í™”)
STYLE_PRESETS = {
    "ê¸°ë³¸": {
        "prompt_prefix": "high quality, detailed, enhanced",
        "guidance_scale": 4.0,
        "num_inference_steps": 30,
    },
    "ğŸ“¸ ì¸ë¬¼ - ìµœê³  í™”ì§ˆ": {
        "prompt_prefix": "ultra high quality portrait, photorealistic, 8k resolution, professional photography, perfect skin texture, natural lighting, detailed facial features, crystal clear, ultra detailed, masterpiece quality, professional grade",
        "guidance_scale": 4.8,
        "num_inference_steps": 40,
    },
    "ğŸ‘¤ ì¸ë¬¼ - ìì—°ìŠ¤ëŸ¬ìš´ ë³´ì •": {
        "prompt_prefix": "natural portrait enhancement, soft lighting, realistic skin texture, subtle improvement, professional quality, high resolution, natural look",
        "guidance_scale": 4.2,
        "num_inference_steps": 35,
    },
    "ğŸ­ ì¸ë¬¼ - ìŠ¤íŠœë””ì˜¤ í’ˆì§ˆ": {
        "prompt_prefix": "studio portrait, professional lighting, perfect skin, high-end photography, commercial quality, flawless details, premium grade",
        "guidance_scale": 5.0,
        "num_inference_steps": 45,
    },
    "ğŸï¸ í’ê²½ - ì„ ëª…ë„ í–¥ìƒ": {
        "prompt_prefix": "stunning landscape, crystal clear details, vibrant colors, high dynamic range, professional landscape photography, ultra sharp, detailed environment",
        "guidance_scale": 4.2,
        "num_inference_steps": 32,
    },
    "ğŸ”ï¸ í’ê²½ - ìì—°ìƒ‰ ë³µì›": {
        "prompt_prefix": "natural landscape colors, realistic atmosphere, balanced exposure, detailed textures, professional nature photography, enhanced clarity",
        "guidance_scale": 3.8,
        "num_inference_steps": 30,
    },
    "ğŸ“¦ ì œí’ˆ/ì‚¬ë¬¼ - ì„ ëª…í•¨": {
        "prompt_prefix": "product photography, studio quality, perfect lighting, sharp details, clean background, professional commercial photography, ultra clear",
        "guidance_scale": 5.2,
        "num_inference_steps": 35,
    },
    "ğŸ” ì œí’ˆ/ì‚¬ë¬¼ - ì§ˆê° ê°•í™”": {
        "prompt_prefix": "detailed texture enhancement, material definition, professional product shot, high resolution details, enhanced surface quality",
        "guidance_scale": 4.8,
        "num_inference_steps": 38,
    },
    "ğŸ“„ ë¬¸ì„œ/í…ìŠ¤íŠ¸ - ê°€ë…ì„±": {
        "prompt_prefix": "document enhancement, clear text, sharp typography, high contrast, readable content, professional document quality, clean scan",
        "guidance_scale": 6.0,
        "num_inference_steps": 28,
    },
    "ğŸ“‹ ë¬¸ì„œ/í…ìŠ¤íŠ¸ - ë°°ê²½ ì •ë¦¬": {
        "prompt_prefix": "clean document, white background, clear text, noise reduction, professional scan quality, enhanced readability",
        "guidance_scale": 5.5,
        "num_inference_steps": 30,
    },
    "ğŸ”§ ì´ë¯¸ì§€ ë³µì› - ì˜¤ë˜ëœ ì‚¬ì§„": {
        "prompt_prefix": "photo restoration, vintage photo enhancement, color correction, damage repair, restored quality, professional restoration",
        "guidance_scale": 4.8,
        "num_inference_steps": 45,
    },
    "âœ¨ ì´ë¯¸ì§€ ë³µì› - ë…¸ì´ì¦ˆ ì œê±°": {
        "prompt_prefix": "noise reduction, image cleanup, quality enhancement, artifact removal, smooth restoration, professional grade",
        "guidance_scale": 4.5,
        "num_inference_steps": 38,
    },
}

# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±
with gr.Blocks(
    title="FLUX.1-Kontext ì´ë¯¸ì§€ í–¥ìƒê¸°",
    theme=gr.themes.Soft(),
) as demo:
    
    # ìƒë‹¨ í—¤ë”
    with gr.Row():
        gr.Markdown(
            """
            # ğŸ¨ FLUX.1-Kontext ì´ë¯¸ì§€ í–¥ìƒê¸°
            ## ğŸ–¼ï¸ **Image-to-Image ì „ìš©**: ê¸°ì¡´ ì´ë¯¸ì§€ë¥¼ ê³ í’ˆì§ˆë¡œ í–¥ìƒì‹œí‚¤ê±°ë‚˜ ìŠ¤íƒ€ì¼ì„ ë³€í™˜í•©ë‹ˆë‹¤!
            ### âœ… **ì›ë³¸ í¬ê¸° ì™„ì „ ìœ ì§€**: ì…ë ¥ ì´ë¯¸ì§€ì™€ ë™ì¼í•œ í¬ê¸°ë¡œ ì¶œë ¥ë©ë‹ˆë‹¤
            """
        )

    # ë©”ì¸ ì´ë¯¸ì§€ ì˜ì—­ (ì¢Œìš° ì •ë ¬)
    with gr.Row(equal_height=True):
        # ì™¼ìª½: ì…ë ¥ ì´ë¯¸ì§€ + ì»¨íŠ¸ë¡¤
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ“¸ ì…ë ¥ ì´ë¯¸ì§€")
            input_image = gr.Image(
                label="ì›ë³¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ (í•„ìˆ˜)",
                type="pil",
                sources=["upload", "clipboard"],
                height=400
            )
            
            # â­ ì…ë ¥ ì´ë¯¸ì§€ ì •ë³´ í‘œì‹œ
            image_info = gr.Textbox(
                label="ğŸ“Š ì´ë¯¸ì§€ ì •ë³´",
                value="ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.",
                interactive=False,
                lines=1
            )
            
            gr.Markdown("### ğŸ¨ ìŠ¤íƒ€ì¼ ì„¤ì •")
            style_preset = gr.Dropdown(
                label="ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹",
                choices=list(STYLE_PRESETS.keys()),
                value="ğŸ“¸ ì¸ë¬¼ - ìµœê³  í™”ì§ˆ",
                info="ìš©ë„ì— ë§ëŠ” ìµœì í™”ëœ ì„¤ì •ì´ ìë™ìœ¼ë¡œ ì ìš©ë©ë‹ˆë‹¤"
            )
            
            prompt_input = gr.Textbox(
                label="ì¶”ê°€ ìš”ì²­ì‚¬í•­ (ì„ íƒì‚¬í•­)",
                placeholder="ì¶”ê°€ë¡œ ì›í•˜ëŠ” ë³€í™˜ì´ë‚˜ ê°œì„ ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”...",
                value="",
                lines=2
            )
            
            # ìƒì„± ë²„íŠ¼
            generate_btn = gr.Button(
                "ğŸ¨ ì´ë¯¸ì§€ í–¥ìƒ ì‹œì‘ (ì›ë³¸ í¬ê¸° ìœ ì§€)", 
                variant="primary", 
                size="lg"
            )

        # ì˜¤ë¥¸ìª½: ì¶œë ¥ ì´ë¯¸ì§€ + ì •ë³´
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ¨ í–¥ìƒëœ ì´ë¯¸ì§€")
            output_image = gr.Image(
                label="í–¥ìƒëœ ì´ë¯¸ì§€ (ì›ë³¸ê³¼ ë™ì¼ í¬ê¸°)",
                type="pil",
                height=400
            )
            
            # ì²˜ë¦¬ ì •ë³´
            info_output = gr.Textbox(
                label="ğŸ“Š ì²˜ë¦¬ ì •ë³´", 
                lines=6, 
                interactive=False
            )

    # â­ ê³ ê¸‰ ì„¤ì • (í”„ë¦¬ì…‹ì— ë”°ë¼ ìë™ ì¡°ì •ë¨)
    with gr.Accordion("âš™ï¸ ê³ ê¸‰ ì„¤ì •", open=False):
        with gr.Row():
            guidance_slider = gr.Slider(
                minimum=1.0,
                maximum=10.0,
                value=4.8,  # ê¸°ë³¸ê°’: ì¸ë¬¼ - ìµœê³  í™”ì§ˆ í”„ë¦¬ì…‹
                step=0.1,
                label="ğŸ“ ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼",
                info="í”„ë¡¬í”„íŠ¸ ì¤€ìˆ˜ ì •ë„ (í”„ë¦¬ì…‹ì— ë”°ë¼ ìë™ ì„¤ì •ë¨)"
            )
            
            steps_slider = gr.Slider(
                minimum=15,
                maximum=50,
                value=40,   # ê¸°ë³¸ê°’: ì¸ë¬¼ - ìµœê³  í™”ì§ˆ í”„ë¦¬ì…‹
                step=1,
                label="âš¡ ì¶”ë¡  ìŠ¤í… ìˆ˜",
                info="ì²˜ë¦¬ ë‹¨ê³„ ìˆ˜ (í”„ë¦¬ì…‹ì— ë”°ë¼ ìë™ ì„¤ì •ë¨)"
            )
            
            seed_input = gr.Number(
                label="ğŸ² ì‹œë“œ (-1ì€ ëœë¤)",
                value=-1,
                precision=0,
                info="ê²°ê³¼ ì¬í˜„ìš©"
            )

    # ì˜ˆì œ í”„ë¡¬í”„íŠ¸
    with gr.Accordion("ğŸ“ ì˜ˆì œ í”„ë¡¬í”„íŠ¸", open=False):
        gr.Examples(
            examples=[
                ["ë” ì„ ëª…í•˜ê³  ê¹¨ë—í•˜ê²Œ"],
                ["ìì—°ìŠ¤ëŸ½ê²Œ ë³´ì •í•´ì£¼ì„¸ìš”"],
                ["í”„ë¡œ ì‚¬ì§„ì‘ê°€ ìŠ¤íƒ€ì¼ë¡œ"],
                ["ë¹ˆí‹°ì§€í•œ ëŠë‚Œìœ¼ë¡œ"],
                ["ë”°ëœ»í•œ ì¡°ëª…ìœ¼ë¡œ"],
                ["í‘ë°± ì˜ˆìˆ  ì‚¬ì§„ìœ¼ë¡œ"],
            ],
            inputs=prompt_input
        )

    # ì‚¬ìš© ê°€ì´ë“œ
    with gr.Accordion("ğŸ’¡ ì‚¬ìš© ê°€ì´ë“œ", open=False):
        gr.Markdown(
            """
            ### ğŸ¯ ì›ë³¸ í¬ê¸° ì™„ì „ ìœ ì§€
            - **ëª¨ë“  ì´ë¯¸ì§€ê°€ ì›ë³¸ê³¼ ë™ì¼í•œ í¬ê¸°ë¡œ ì¶œë ¥ë©ë‹ˆë‹¤**
            - 1920x1080 ì…ë ¥ â†’ 1920x1080 ì¶œë ¥
            - 800x600 ì…ë ¥ â†’ 800x600 ì¶œë ¥
            - ì–´ë–¤ í¬ê¸°ë“  ì™„ì „íˆ ë™ì¼í•˜ê²Œ ìœ ì§€
            
            ### ğŸ‘¤ ì¸ë¬¼ ì‚¬ì§„ ìµœì í™”
            - **ğŸ“¸ ìµœê³  í™”ì§ˆ**: 8K ì „ë¬¸ê°€ê¸‰ í’ˆì§ˆ (ê°€ì´ë˜ìŠ¤: 4.8, ìŠ¤í…: 40)
            - **ğŸ‘¤ ìì—°ìŠ¤ëŸ¬ìš´ ë³´ì •**: ê³¼í•˜ì§€ ì•Šì€ ê°œì„  (ê°€ì´ë˜ìŠ¤: 4.2, ìŠ¤í…: 35)
            - **ğŸ­ ìŠ¤íŠœë””ì˜¤ í’ˆì§ˆ**: ìƒì—…ì  í’ˆì§ˆ (ê°€ì´ë˜ìŠ¤: 5.0, ìŠ¤í…: 45)
            
            ### ğŸ’¡ ì‚¬ìš©ë²•
            1. ì´ë¯¸ì§€ ì—…ë¡œë“œ (ì–´ë–¤ í¬ê¸°ë“  ê°€ëŠ¥)
            2. ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹ ì„ íƒ (ìë™ìœ¼ë¡œ ìµœì  ì„¤ì • ì ìš©)
            3. í•„ìš” ì‹œ ì¶”ê°€ ìš”ì²­ì‚¬í•­ ì…ë ¥
            4. 'ì´ë¯¸ì§€ í–¥ìƒ ì‹œì‘' ë²„íŠ¼ í´ë¦­
            5. ì›ë³¸ê³¼ ë™ì¼í•œ í¬ê¸°ì˜ í–¥ìƒëœ ì´ë¯¸ì§€ íšë“
            """
        )

    # â­ ì´ë²¤íŠ¸ ì—°ê²°
    input_image.change(
        fn=show_image_info,
        inputs=[input_image],
        outputs=[image_info]
    )
    
    style_preset.change(
        fn=apply_preset_settings,
        inputs=[style_preset],
        outputs=[guidance_slider, steps_slider],
    )

    generate_btn.click(
        fn=generate_image,
        inputs=[
            prompt_input,
            input_image,
            gr.State(768),  # width (ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)
            gr.State(768),  # height (ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)
            guidance_slider,
            steps_slider,
            gr.State(320),  # max_sequence_length
            seed_input,
        ],
        outputs=[output_image, info_output],
        show_progress=True,
    )

if __name__ == "__main__":
    demo.launch(
        share=False,
        inbrowser=True,
    )
