import torch
import gradio as gr
import time
from diffusers import FluxKontextPipeline
from PIL import Image
import datetime


def loading_model():
    model_id = "black-forest-labs/FLUX.1-Kontext-dev"
    print("ëª¨ë¸ì„ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤...")
    pipe = FluxKontextPipeline.from_pretrained(model_id, torch_dtype=torch.bfloat16)

    # CPU ì˜¤í”„ë¡œë“œ ë° Attention ìŠ¬ë¼ì´ì‹± í™œì„±í™”
    pipe.enable_model_cpu_offload()
    pipe.enable_sequential_cpu_offload()
    pipe.enable_attention_slicing(1)
    pipe.enable_vae_slicing()
    print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
    return pipe


# ë¡œë”©ëœ ëª¨ë¸ì„ ì „ì—­ ë³€ìˆ˜ë¡œ ì €ì¥
pipe = loading_model()

MAX_IMAGE_SIZE = 1024
def resize_image(input_image):
    w, h = input_image.size
    max_side = max(w, h)
    if max_side > MAX_IMAGE_SIZE:
        scale = MAX_IMAGE_SIZE / max_side
        w_new = int(w * scale)
        h_new = int(h * scale)
    else:
        w_new, h_new = w, h
    # Make both dimensions multiples of 16
    w_new = (w_new // 16) * 16
    h_new = (h_new // 16) * 16
    # Avoid zero size
    w_new = max(w_new, 16)
    h_new = max(h_new, 16)
    resized_image = input_image.resize((w_new, h_new), Image.Resampling.LANCZOS)
    return resized_image


def generate_image(
    prompt,
    negative_prompt,
    input_image,
    guidance_scale,
    steps,
    seq_len,
    seed,
):
    start = time.time()

    if input_image is None:
        return None, "ì´ë¯¸ì§€-íˆ¬-ì´ë¯¸ì§€ë§Œ ì§€ì›í•©ë‹ˆë‹¤. ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”."

    input_image = resize_image(input_image)  # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
    info = f"\nì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°: {input_image.size[0]}x{input_image.size[1]}"
    # Generator ì„¤ì •
    if seed == -1:
        seed = torch.randint(0, 2**32 - 1, (1,)).item()
    generator = torch.Generator("cpu").manual_seed(seed)

    try:
        image = pipe(
            prompt=prompt,
            negative_prompt=negative_prompt,
            image=input_image,
            width=input_image.size[0],
            height=input_image.size[1],
            guidance_scale=guidance_scale,
            num_inference_steps=int(steps),
            max_sequence_length=int(seq_len),
            generator=generator,
        ).images[0]

        # ê³ í’ˆì§ˆ ì €ì¥ ì„¤ì •
        filename = f"Flux1-Kontext-dev-example15_{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}.png"
        image.save(
            filename, format="PNG", compress_level=1, optimize=False
        )  # ìµœê³  í’ˆì§ˆë¡œ ì €ì¥
        info_text = (
            f"ìƒì„± ì™„ë£Œ! (ì´ë¯¸ì§€ íˆ¬ ì´ë¯¸ì§€)\nì‹œê°„: {time.time()-start:.2f}ì´ˆ\nì‹œë“œ: {seed}\nì €ì¥ëœ íŒŒì¼: {filename}"
            f"\nìƒì„±ëœ ì´ë¯¸ì§€ í¬ê¸°: {image.size[0]}x{image.size[1]}{info}"
        )
        return image, info_text
    except Exception as e:
        return None, f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±
with gr.Blocks(title="FLUX.1 Kontext Dev ì´ë¯¸ì§€ ìƒì„±ê¸°") as demo:
    gr.Markdown("# ğŸ¨ FLUX.1 Kontext Devì´ë¯¸ì§€ ìƒì„±ê¸°")

    with gr.Row():
        with gr.Column():
            # ì…ë ¥ ì´ë¯¸ì§€ (ì„ íƒì‚¬í•­)
            input_image = gr.Image(
                label="ì…ë ¥ ì´ë¯¸ì§€ (ì„ íƒì‚¬í•­)",
                type="pil",
                sources=["upload", "clipboard"],
                height=500,
                value="default16.jpg",
            )

            # ì…ë ¥ ì»¨íŠ¸ë¡¤ë“¤
            prompt_input = gr.Textbox(
                label="í”„ë¡¬í”„íŠ¸",
                placeholder="ìƒì„±í•˜ê³  ì‹¶ì€ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”...",
                value="8k, high detail, high quality, best quality, masterpiece, dark blue bikini",
                lines=4,
            )

            negative_prompt_input = gr.Textbox(
                label="ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸",
                placeholder="ì›í•˜ì§€ ì•ŠëŠ” ìš”ì†Œë¥¼ ì…ë ¥í•˜ì„¸ìš”...",
                value="blurring, low quality, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, normal quality, jpeg artifacts, signature, watermark, username",
                lines=2,
            )

            guidance_slider = gr.Slider(
                minimum=1.0,
                maximum=10.0,  # ë²”ìœ„ í™•ì¥
                value=3.5,  # ë” ë†’ì€ ê¸°ë³¸ê°’
                step=0.1,
                label="ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼",
                info="í”„ë¡¬í”„íŠ¸ ì¤€ìˆ˜ ì •ë„. ë†’ì„ìˆ˜ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ ë” ì •í™•íˆ ë”°ë¥´ì§€ë§Œ ì°½ì˜ì„±ì´ ì¤„ì–´ë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ê¶Œì¥: 7.0-10.0)",
            )

            steps_slider = gr.Slider(
                minimum=10,
                maximum=50,  # ë” ë†’ì€ ìµœëŒ€ê°’
                value=35,  # ë” ë†’ì€ ê¸°ë³¸ê°’
                step=1,
                label="ì¶”ë¡  ìŠ¤í… ìˆ˜",
                info="ì´ë¯¸ì§€ ìƒì„± ë‹¨ê³„ ìˆ˜. ë†’ì„ìˆ˜ë¡ í’ˆì§ˆì´ í–¥ìƒë˜ì§€ë§Œ ìƒì„± ì‹œê°„ì´ ëŠ˜ì–´ë‚©ë‹ˆë‹¤. (ìµœê³  í’ˆì§ˆ: 50-80)",
            )

            sequence_slider = gr.Slider(
                minimum=256,
                maximum=1024,  # ë” ë†’ì€ ìµœëŒ€ê°’
                value=512,  # ë” ë†’ì€ ê¸°ë³¸ê°’
                step=64,
                label="ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´",
                info="í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ ê¸¸ì´. ê¸´ í”„ë¡¬í”„íŠ¸ì—ëŠ” ë†’ì€ ê°’ì´ í•„ìš”í•©ë‹ˆë‹¤. (ìµœê³  í’ˆì§ˆ: 512-1024)",
            )

            seed_input = gr.Number(
                label="ì‹œë“œ (-1ì€ ëœë¤)",
                value=42,
                precision=0,
                info="ìƒì„± ê²°ê³¼ì˜ ì¼ê´€ì„±ì„ ìœ„í•œ ë‚œìˆ˜ ì‹œë“œ. ê°™ì€ ì‹œë“œë¡œ ê°™ì€ ì„¤ì •ì´ë©´ ë¹„ìŠ·í•œ ê²°ê³¼ê°€ ë‚˜ì˜µë‹ˆë‹¤. -1ì€ ë¬´ì‘ìœ„ ì‹œë“œ ì‚¬ìš©",
            )

            generate_btn = gr.Button("ğŸ¨ ì´ë¯¸ì§€ ìƒì„±", variant="primary", size="lg")

        with gr.Column():
            # ì¶œë ¥ ì˜ì—­
            output_image = gr.Image(label="ìƒì„±ëœ ì´ë¯¸ì§€", type="pil")
            info_output = gr.Textbox(label="ìƒì„± ì •ë³´", lines=4, interactive=False)

    # ì´ë²¤íŠ¸ ì—°ê²°
    generate_btn.click(
        fn=generate_image,
        inputs=[
            prompt_input,
            negative_prompt_input,  # ì¶”ê°€
            input_image,
            guidance_slider,
            steps_slider,
            sequence_slider,
            seed_input,
        ],
        outputs=[output_image, info_output],
    )

if __name__ == "__main__":
    demo.launch(inbrowser=True)
