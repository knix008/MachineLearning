import torch
import gradio as gr
import time
from diffusers import FluxKontextPipeline
from diffusers.utils import load_image
from PIL import Image
import os

# Dependency!!! :
# You need to install the diffusers with the following command:
# pip install git+https://github.com/huggingface/diffusers.git

# Load model with memory optimizations
print("ëª¨ë¸ì„ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤...")
pipe = FluxKontextPipeline.from_pretrained(
    "black-forest-labs/FLUX.1-Kontext-dev", torch_dtype=torch.bfloat16
)

# Enable multiple memory optimizations
pipe.enable_model_cpu_offload()  # Offload model to CPU when not in use
pipe.enable_sequential_cpu_offload()  # More aggressive CPU offloading
pipe.enable_attention_slicing(1)  # Slice attention computation
pipe.enable_vae_slicing()  # Slice VAE computation
print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")


def generate_image(
    prompt,
    input_image,
    width,
    height,
    guidance_scale,
    num_inference_steps,
    max_sequence_length,
    seed,
):
    """ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ (í…ìŠ¤íŠ¸-íˆ¬-ì´ë¯¸ì§€ ë˜ëŠ” ì´ë¯¸ì§€-íˆ¬-ì´ë¯¸ì§€)"""
    start_time = time.time()

    # ì…ë ¥ ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° í•´ë‹¹ ì´ë¯¸ì§€ì˜ ë¹„ìœ¨ ì‚¬ìš©
    if input_image is not None:
        input_width, input_height = input_image.size
        aspect_ratio = input_width / input_height

        # ì…ë ¥ ì´ë¯¸ì§€ ë¹„ìœ¨ì— ë§ì¶° í¬ê¸° ì¡°ì •
        if aspect_ratio >= 1.0:  # ê°€ë¡œê°€ ë” í¬ê±°ë‚˜ ê°™ì€ ê²½ìš°
            adjusted_width = max(768, int(width))
            adjusted_height = int(adjusted_width / aspect_ratio)
        else:  # ì„¸ë¡œê°€ ë” í° ê²½ìš°
            adjusted_height = max(768, int(height))
            adjusted_width = int(adjusted_height * aspect_ratio)

        # 16ì˜ ë°°ìˆ˜ë¡œ ì¡°ì •
        adjusted_width = (adjusted_width // 16) * 16
        adjusted_height = (adjusted_height // 16) * 16

        # ìµœì†Œ í¬ê¸° ë³´ì¥
        adjusted_width = max(adjusted_width, 512)
        adjusted_height = max(adjusted_height, 512)

        generation_type = "ì´ë¯¸ì§€ íˆ¬ ì´ë¯¸ì§€"

    else:
        # ì‚¬ìš©ì ì§€ì • í¬ê¸° ì‚¬ìš© (í…ìŠ¤íŠ¸-íˆ¬-ì´ë¯¸ì§€)
        width = int(width)
        height = int(height)
        aspect_ratio = width / height

        # 16ì˜ ë°°ìˆ˜ë¡œ ì¡°ì •
        adjusted_width = (width // 16) * 16
        adjusted_height = (height // 16) * 16

        # ìµœì†Œ í¬ê¸° ë³´ì¥í•˜ë©´ì„œ ë¹„ìœ¨ ìœ ì§€
        if adjusted_width < 512 or adjusted_height < 512:
            if aspect_ratio >= 1.0:  # ê°€ë¡œê°€ ë” í¬ê±°ë‚˜ ê°™ì€ ê²½ìš°
                adjusted_height = 512
                adjusted_width = int(512 * aspect_ratio)
                adjusted_width = (adjusted_width // 16) * 16
            else:  # ì„¸ë¡œê°€ ë” í° ê²½ìš°
                adjusted_width = 512
                adjusted_height = int(512 / aspect_ratio)
                adjusted_height = (adjusted_height // 16) * 16

        # ìµœì¢… ìµœì†Œ í¬ê¸° í™•ì¸
        adjusted_width = max(adjusted_width, 512)
        adjusted_height = max(adjusted_height, 512)

        generation_type = "í…ìŠ¤íŠ¸ íˆ¬ ì´ë¯¸ì§€"

    # ì‹œë“œ ì„¤ì •
    if seed == -1:
        seed = torch.randint(0, 2**32 - 1, (1,)).item()

    generator = torch.Generator("cpu").manual_seed(seed)

    try:
        # ì…ë ¥ ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° img2img, ì—†ëŠ” ê²½ìš° txt2img
        if input_image is not None:
            # ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
            input_image = input_image.resize(
                (adjusted_width, adjusted_height), Image.LANCZOS
            )

            # img2img ìƒì„±
            image = pipe(
                prompt=prompt,
                image=input_image,
                height=adjusted_height,
                width=adjusted_width,
                guidance_scale=guidance_scale,
                num_inference_steps=int(num_inference_steps),
                max_sequence_length=int(max_sequence_length),
                generator=generator,
            ).images[0]

        else:
            # txt2img ìƒì„±
            image = pipe(
                prompt=prompt,
                height=adjusted_height,
                width=adjusted_width,
                guidance_scale=guidance_scale,
                num_inference_steps=int(num_inference_steps),
                max_sequence_length=int(max_sequence_length),
                generator=generator,
            ).images[0]

        end_time = time.time()
        generation_time = end_time - start_time

        # ì´ë¯¸ì§€ ì €ì¥
        timestamp = int(time.time())
        filename = f"flux_generated_{timestamp}.png"
        image.save(filename)

        # ìƒì„±ëœ ì´ë¯¸ì§€ í¬ê¸° ì •ë³´
        generated_width, generated_height = image.size

        # í¬ê¸° ì¡°ì • ì •ë³´ í¬í•¨
        size_info = f"\nìƒì„±ëœ ì´ë¯¸ì§€ í¬ê¸°: {generated_width}x{generated_height}"
        if input_image is not None:
            # ì›ë³¸ input_image ì •ë³´ ì‚¬ìš© (ë¦¬ì‚¬ì´ì¦ˆ ì „)
            size_info += (
                f"\nì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°: {input_image.size[0]}x{input_image.size[1]}"
            )
            size_info += f"\në¹„ìœ¨ ë§ì¶¤: {input_image.size[0]/input_image.size[1]:.2f} â†’ {generated_width/generated_height:.2f}"
        else:
            size_info += f"\nìš”ì²­ í¬ê¸°: {width}x{height}"

        info_text = f"ìƒì„± ì™„ë£Œ! ({generation_type})\nì‹œê°„: {generation_time:.2f}ì´ˆ\nì‹œë“œ: {seed}\nì €ì¥ëœ íŒŒì¼: {filename}{size_info}"

        return image, info_text

    except Exception as e:
        error_text = f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        return None, error_text


# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±
with gr.Blocks(title="FLUX.1-dev ì´ë¯¸ì§€ ìƒì„±ê¸°") as demo:
    gr.Markdown("# ğŸ¨ FLUX.1-dev ì´ë¯¸ì§€ ìƒì„±ê¸°")
    gr.Markdown(
        "í…ìŠ¤íŠ¸ë¡œ ìƒˆ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê±°ë‚˜, ê¸°ì¡´ ì´ë¯¸ì§€ë¥¼ í”„ë¡¬í”„íŠ¸ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”!"
    )

    with gr.Row():
        with gr.Column(scale=1):
            # ì…ë ¥ ì´ë¯¸ì§€ (ì„ íƒì‚¬í•­)
            input_image = gr.Image(
                label="ì…ë ¥ ì´ë¯¸ì§€ (ì„ íƒì‚¬í•­)",
                type="pil",
                sources=["upload", "clipboard"],
            )

            # ì…ë ¥ ì»¨íŠ¸ë¡¤ë“¤
            prompt_input = gr.Textbox(
                label="í”„ë¡¬í”„íŠ¸",
                placeholder="ìƒì„±í•˜ê³  ì‹¶ì€ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”...",
                value="blue bikini, blue eyes, beautiful face, good body shape, good hair, good fingers, good legs, photorealistic, 8k resolution, ultra detailed, vibrant colors, cinematic lighting, realistic shadows, high quality, masterpiece, best quality, looking at viewer, perfect anatomy",
                lines=4,
            )

            with gr.Row():
                width_slider = gr.Slider(
                    minimum=256,
                    maximum=1024,
                    value=768,
                    step=64,
                    label="ë„ˆë¹„",
                    info="ìƒì„±í•  ì´ë¯¸ì§€ì˜ ë„ˆë¹„ (í”½ì…€). ë†’ì„ìˆ˜ë¡ ë” ë„“ì€ ì´ë¯¸ì§€ê°€ ìƒì„±ë©ë‹ˆë‹¤.",
                )
                height_slider = gr.Slider(
                    minimum=256,
                    maximum=1024,
                    value=768,
                    step=64,
                    label="ë†’ì´",
                    info="ìƒì„±í•  ì´ë¯¸ì§€ì˜ ë†’ì´ (í”½ì…€). ë†’ì„ìˆ˜ë¡ ë” ê¸´ ì´ë¯¸ì§€ê°€ ìƒì„±ë©ë‹ˆë‹¤.",
                )

            guidance_slider = gr.Slider(
                minimum=1.0,
                maximum=10.0,
                value=3.5,
                step=0.1,
                label="ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼",
                info="í”„ë¡¬í”„íŠ¸ ì¤€ìˆ˜ ì •ë„. ë†’ì„ìˆ˜ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ ë” ì •í™•íˆ ë”°ë¥´ì§€ë§Œ ì°½ì˜ì„±ì´ ì¤„ì–´ë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ê¶Œì¥: 3.5-7.5)",
            )

            steps_slider = gr.Slider(
                minimum=10,
                maximum=50,
                value=28,
                step=1,
                label="ì¶”ë¡  ìŠ¤í… ìˆ˜",
                info="ì´ë¯¸ì§€ ìƒì„± ë‹¨ê³„ ìˆ˜. ë†’ì„ìˆ˜ë¡ í’ˆì§ˆì´ í–¥ìƒë˜ì§€ë§Œ ìƒì„± ì‹œê°„ì´ ëŠ˜ì–´ë‚©ë‹ˆë‹¤. (ê¶Œì¥: 20-30)",
            )

            sequence_slider = gr.Slider(
                minimum=128,
                maximum=512,
                value=256,
                step=32,
                label="ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´",
                info="í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ ê¸¸ì´. ê¸´ í”„ë¡¬í”„íŠ¸ì—ëŠ” ë†’ì€ ê°’ì´ í•„ìš”í•©ë‹ˆë‹¤. (ê¸°ë³¸: 256)",
            )

            seed_input = gr.Number(
                label="ì‹œë“œ (-1ì€ ëœë¤)",
                value=-1,
                precision=0,
                info="ìƒì„± ê²°ê³¼ì˜ ì¼ê´€ì„±ì„ ìœ„í•œ ë‚œìˆ˜ ì‹œë“œ. ê°™ì€ ì‹œë“œë¡œ ê°™ì€ ì„¤ì •ì´ë©´ ë¹„ìŠ·í•œ ê²°ê³¼ê°€ ë‚˜ì˜µë‹ˆë‹¤. -1ì€ ë¬´ì‘ìœ„ ì‹œë“œ ì‚¬ìš©",
            )

            generate_btn = gr.Button("ğŸ¨ ì´ë¯¸ì§€ ìƒì„±", variant="primary", size="lg")

            # ì„¤ì • ê°€ì´ë“œ ì¶”ê°€
            with gr.Accordion("ğŸ“š ì„¤ì • ê°€ì´ë“œ", open=False):
                gr.Markdown(
                    """
                ### ğŸ¯ ì£¼ìš” ì„¤ì • ì„¤ëª…
                
                **ğŸ¨ ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼ (Guidance Scale)**
                - 1.0-3.0: ì°½ì˜ì ì´ê³  ë‹¤ì–‘í•œ ê²°ê³¼, í”„ë¡¬í”„íŠ¸ë¥¼ ëŠìŠ¨í•˜ê²Œ ë”°ë¦„
                - 3.5-7.5: ê· í˜•ì¡íŒ ê²°ê³¼ (ê¶Œì¥)
                - 8.0-10.0: í”„ë¡¬í”„íŠ¸ë¥¼ ë§¤ìš° ì •í™•íˆ ë”°ë¥´ì§€ë§Œ ì°½ì˜ì„± ë¶€ì¡±
                
                **âš¡ ì¶”ë¡  ìŠ¤í… ìˆ˜ (Inference Steps)**
                - 10-15: ë¹ ë¥¸ ìƒì„±, ë‚®ì€ í’ˆì§ˆ
                - 20-30: ê· í˜•ì¡íŒ í’ˆì§ˆê³¼ ì†ë„ (ê¶Œì¥)
                - 35-50: ë†’ì€ í’ˆì§ˆ, ê¸´ ìƒì„± ì‹œê°„
                
                **ğŸ“ ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ (Max Sequence Length)**
                - 128-192: ì§§ì€ í”„ë¡¬í”„íŠ¸ìš©, ë¹ ë¥¸ ì²˜ë¦¬
                - 256: í‘œì¤€ ê¸¸ì´, ëŒ€ë¶€ë¶„ì˜ í”„ë¡¬í”„íŠ¸ì— ì í•© (ê¶Œì¥)
                - 320-512: ê¸´ í”„ë¡¬í”„íŠ¸ìš©, ë³µì¡í•œ ì„¤ëª… ì²˜ë¦¬ ê°€ëŠ¥
                - ë†’ì„ìˆ˜ë¡ ë” ê¸´ í”„ë¡¬í”„íŠ¸ë¥¼ ì •í™•íˆ ì²˜ë¦¬í•˜ì§€ë§Œ ì²˜ë¦¬ ì‹œê°„ ì¦ê°€
                
                **ğŸ² ì‹œë“œ (Seed)**
                - -1: ë§¤ë²ˆ ë‹¤ë¥¸ ê²°ê³¼ ìƒì„±
                - ê³ ì •ê°’: ê°™ì€ ì„¤ì •ìœ¼ë¡œ ì¼ê´€ëœ ê²°ê³¼ ìƒì„±
                - ì¢‹ì€ ê²°ê³¼ê°€ ë‚˜ì˜¤ë©´ ì‹œë“œë¥¼ ê¸°ë¡í•´ë‘ì„¸ìš”!
                """
                )

        with gr.Column(scale=1):
            # ì¶œë ¥ ì˜ì—­
            output_image = gr.Image(label="ìƒì„±ëœ ì´ë¯¸ì§€", type="pil", height=500)

            info_output = gr.Textbox(label="ìƒì„± ì •ë³´", lines=4, interactive=False)

    # ì´ë²¤íŠ¸ ì—°ê²°
    generate_btn.click(
        fn=generate_image,
        inputs=[
            prompt_input,
            input_image,
            width_slider,
            height_slider,
            guidance_slider,
            steps_slider,
            sequence_slider,
            seed_input,
        ],
        outputs=[output_image, info_output],
    )

    # ì˜ˆì œ í”„ë¡¬í”„íŠ¸
    gr.Examples(
        examples=[
            ["a cute cat holding a sign that says hello world"],
            ["a futuristic city skyline at sunset, cyberpunk style"],
            ["a beautiful landscape with mountains and a lake, oil painting style"],
            ["a portrait of a woman with blue eyes, renaissance painting style"],
            ["a magical forest with glowing mushrooms, fantasy art"],
            ["convert this image to anime style, vibrant colors"],
            ["make this image look like a watercolor painting"],
            ["transform this to a cyberpunk style with neon lights"],
        ],
        inputs=prompt_input,
    )

    # ì‚¬ìš© íŒ ì¶”ê°€
    with gr.Accordion("ğŸ’¡ ì‚¬ìš© íŒ", open=False):
        gr.Markdown(
            """
        ### ğŸš€ íš¨ê³¼ì ì¸ ì‚¬ìš©ë²•
        
        **ğŸ“ í”„ë¡¬í”„íŠ¸ ì‘ì„± íŒ**
        - êµ¬ì²´ì ì´ê³  ëª…í™•í•œ ì„¤ëª… ì‚¬ìš©
        - ìŠ¤íƒ€ì¼ í‚¤ì›Œë“œ í¬í•¨: "photorealistic", "oil painting", "anime style" ë“±
        - í’ˆì§ˆ í‚¤ì›Œë“œ ì¶”ê°€: "high quality", "detailed", "masterpiece" ë“±
        - ê¸´ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© ì‹œ ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ 320-512ë¡œ ì¦ê°€
        
        **ğŸ¨ ìƒˆ ì´ë¯¸ì§€ ìƒì„± (Text-to-Image)**
        - ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼: 3.5-7.5
        - ì¶”ë¡  ìŠ¤í…: 25-30
        - í•´ìƒë„: 768x768 ë˜ëŠ” 1024x1024
        - ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´: 256 (í‘œì¤€), ê¸´ í”„ë¡¬í”„íŠ¸ ì‹œ 512
        
        **ğŸ–¼ï¸ ì´ë¯¸ì§€ ìˆ˜ì • (Image-to-Image)**
        - ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ì— ë§ê²Œ ìˆ˜ì •
        - ì›ë³¸ ì´ë¯¸ì§€ì˜ êµ¬ì¡°ì™€ ë‚´ìš©ì„ ìœ ì§€í•˜ë©´ì„œ ë³€í˜•
        - ë³µì¡í•œ ìˆ˜ì • ìš”ì²­ ì‹œ ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ë†’ì—¬ë³´ì„¸ìš”
        
        **âš¡ ì„±ëŠ¥ ìµœì í™”**
        - ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ: í•´ìƒë„ë¥¼ 512x512ë¡œ ë‚®ì¶”ê¸°
        - ë¹ ë¥¸ ìƒì„±: ì¶”ë¡  ìŠ¤í… 15-20, ì‹œí€€ìŠ¤ ê¸¸ì´ 192-256
        - ê³ í’ˆì§ˆ ìƒì„±: ì¶”ë¡  ìŠ¤í… 30-40, ì‹œí€€ìŠ¤ ê¸¸ì´ 256-320
        """
        )

if __name__ == "__main__":
    demo.launch(share=False, inbrowser=True)
